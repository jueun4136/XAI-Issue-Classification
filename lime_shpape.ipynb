{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8459c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"my_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642b69a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "issue_label\n",
      "bug            10\n",
      "enhancement    10\n",
      "question       10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SRC = \"../data/github-labels-top3-803k-test.csv\"\n",
    "label_col = \"issue_label\"\n",
    "target_labels = [\"bug\", \"enhancement\", \"question\"]\n",
    "n_per_class = 10\n",
    "\n",
    "df_all = pd.read_csv(SRC)\n",
    "df_all = df_all[df_all[label_col].isin(target_labels)]\n",
    "\n",
    "\n",
    "df_eval = (\n",
    "    df_all.groupby(label_col, group_keys=False)\n",
    "    .sample(n=n_per_class, random_state=200)\n",
    "    .sort_values([label_col])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_eval.to_csv(\"balanced_eval_set.csv\", index=False)\n",
    "\n",
    "print(df_eval[label_col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983b13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e22da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LIME 00] gold: bug | pred: bug (conf 0.93)\n",
      "\n",
      "[LIME 01] gold: bug | pred: bug (conf 0.93)\n",
      "\n",
      "[LIME 02] gold: bug | pred: bug (conf 0.79)\n",
      "\n",
      "[LIME 03] gold: bug | pred: bug (conf 0.90)\n",
      "\n",
      "[LIME 04] gold: bug | pred: bug (conf 0.95)\n",
      "\n",
      "[LIME 05] gold: bug | pred: bug (conf 0.94)\n",
      "\n",
      "[LIME 06] gold: bug | pred: bug (conf 0.95)\n",
      "\n",
      "[LIME 07] gold: bug | pred: bug (conf 0.95)\n",
      "\n",
      "[LIME 08] gold: bug | pred: question (conf 0.57)\n",
      "\n",
      "[LIME 09] gold: bug | pred: bug (conf 0.92)\n",
      "\n",
      "[LIME 10] gold: enhancement | pred: enhancement (conf 0.98)\n",
      "\n",
      "[LIME 11] gold: enhancement | pred: enhancement (conf 0.95)\n",
      "\n",
      "[LIME 12] gold: enhancement | pred: enhancement (conf 0.91)\n",
      "\n",
      "[LIME 13] gold: enhancement | pred: enhancement (conf 0.85)\n",
      "\n",
      "[LIME 14] gold: enhancement | pred: enhancement (conf 0.82)\n",
      "\n",
      "[LIME 15] gold: enhancement | pred: enhancement (conf 0.98)\n",
      "\n",
      "[LIME 16] gold: enhancement | pred: enhancement (conf 0.98)\n",
      "\n",
      "[LIME 17] gold: enhancement | pred: enhancement (conf 0.96)\n",
      "\n",
      "[LIME 18] gold: enhancement | pred: bug (conf 0.97)\n",
      "\n",
      "[LIME 19] gold: enhancement | pred: enhancement (conf 0.97)\n",
      "\n",
      "[LIME 20] gold: question | pred: question (conf 0.44)\n",
      "\n",
      "[LIME 21] gold: question | pred: bug (conf 0.56)\n",
      "\n",
      "[LIME 22] gold: question | pred: bug (conf 0.60)\n",
      "\n",
      "[LIME 23] gold: question | pred: enhancement (conf 0.63)\n",
      "\n",
      "[LIME 24] gold: question | pred: bug (conf 0.71)\n",
      "\n",
      "[LIME 25] gold: question | pred: question (conf 0.69)\n",
      "\n",
      "[LIME 26] gold: question | pred: question (conf 0.61)\n",
      "\n",
      "[LIME 27] gold: question | pred: enhancement (conf 0.48)\n",
      "\n",
      "[LIME 28] gold: question | pred: question (conf 0.92)\n",
      "\n",
      "[LIME 29] gold: question | pred: question (conf 0.41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 31it [00:55,  2.06s/it]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SHAP ready: 30 samples\n",
      "[SHAP 00] saved → shap_00.html (pred=bug, p=0.93)\n",
      "[SHAP 01] saved → shap_01.html (pred=bug, p=0.93)\n",
      "[SHAP 02] saved → shap_02.html (pred=bug, p=0.79)\n",
      "[SHAP 03] saved → shap_03.html (pred=bug, p=0.90)\n",
      "[SHAP 04] saved → shap_04.html (pred=bug, p=0.95)\n",
      "[SHAP 05] saved → shap_05.html (pred=bug, p=0.94)\n",
      "[SHAP 06] saved → shap_06.html (pred=bug, p=0.95)\n",
      "[SHAP 07] saved → shap_07.html (pred=bug, p=0.95)\n",
      "[SHAP 08] saved → shap_08.html (pred=question, p=0.57)\n",
      "[SHAP 09] saved → shap_09.html (pred=bug, p=0.92)\n",
      "[SHAP 10] saved → shap_10.html (pred=enhancement, p=0.98)\n",
      "[SHAP 11] saved → shap_11.html (pred=enhancement, p=0.95)\n",
      "[SHAP 12] saved → shap_12.html (pred=enhancement, p=0.91)\n",
      "[SHAP 13] saved → shap_13.html (pred=enhancement, p=0.85)\n",
      "[SHAP 14] saved → shap_14.html (pred=enhancement, p=0.82)\n",
      "[SHAP 15] saved → shap_15.html (pred=enhancement, p=0.98)\n",
      "[SHAP 16] saved → shap_16.html (pred=enhancement, p=0.98)\n",
      "[SHAP 17] saved → shap_17.html (pred=enhancement, p=0.96)\n",
      "[SHAP 18] saved → shap_18.html (pred=bug, p=0.97)\n",
      "[SHAP 19] saved → shap_19.html (pred=enhancement, p=0.97)\n",
      "[SHAP 20] saved → shap_20.html (pred=question, p=0.44)\n",
      "[SHAP 21] saved → shap_21.html (pred=bug, p=0.56)\n",
      "[SHAP 22] saved → shap_22.html (pred=bug, p=0.60)\n",
      "[SHAP 23] saved → shap_23.html (pred=enhancement, p=0.63)\n",
      "[SHAP 24] saved → shap_24.html (pred=bug, p=0.71)\n",
      "[SHAP 25] saved → shap_25.html (pred=question, p=0.69)\n",
      "[SHAP 26] saved → shap_26.html (pred=question, p=0.61)\n",
      "[SHAP 27] saved → shap_27.html (pred=enhancement, p=0.48)\n",
      "[SHAP 28] saved → shap_28.html (pred=question, p=0.92)\n",
      "[SHAP 29] saved → shap_29.html (pred=question, p=0.41)\n",
      "\n",
      "=== 전체 평균 ===\n",
      "    comprehensiveness  comp_norm  sufficiency  suff_abs\n",
      "k                                                      \n",
      "5               0.039      0.059        0.402     0.422\n",
      "10              0.111      0.162        0.367     0.389\n",
      "20              0.159      0.218        0.349     0.366\n",
      "\n",
      "=== GOLD 라벨별 평균 ===\n",
      "                comprehensiveness  comp_norm  sufficiency  suff_abs\n",
      "k  gold                                                            \n",
      "5  bug                      0.002     -0.004        0.566     0.566\n",
      "   enhancement              0.066      0.080        0.332     0.343\n",
      "   question                 0.048      0.102        0.309     0.356\n",
      "10 bug                      0.068      0.074        0.504     0.507\n",
      "   enhancement              0.126      0.142        0.289     0.307\n",
      "   question                 0.137      0.269        0.306     0.352\n",
      "20 bug                      0.111      0.139        0.502     0.502\n",
      "   enhancement              0.231      0.251        0.292     0.292\n",
      "   question                 0.134      0.264        0.253     0.305\n",
      "\n",
      "Saved: faithfulness_results.csv\n",
      "saved (LIME): lime_00.png\n",
      "saved (LIME): lime_01.png\n",
      "saved (LIME): lime_02.png\n",
      "saved (LIME): lime_03.png\n",
      "saved (LIME): lime_04.png\n",
      "saved (LIME): lime_05.png\n",
      "saved (LIME): lime_06.png\n",
      "saved (LIME): lime_07.png\n",
      "saved (LIME): lime_08.png\n",
      "saved (LIME): lime_09.png\n",
      "saved (LIME): lime_10.png\n",
      "saved (LIME): lime_11.png\n",
      "saved (LIME): lime_12.png\n",
      "saved (LIME): lime_13.png\n",
      "saved (LIME): lime_14.png\n",
      "saved (LIME): lime_15.png\n",
      "saved (LIME): lime_16.png\n",
      "saved (LIME): lime_17.png\n",
      "saved (LIME): lime_18.png\n",
      "saved (LIME): lime_19.png\n",
      "saved (LIME): lime_20.png\n",
      "saved (LIME): lime_21.png\n",
      "saved (LIME): lime_22.png\n",
      "saved (LIME): lime_23.png\n",
      "saved (LIME): lime_24.png\n",
      "saved (LIME): lime_25.png\n",
      "saved (LIME): lime_26.png\n",
      "saved (LIME): lime_27.png\n",
      "saved (LIME): lime_28.png\n",
      "saved (LIME): lime_29.png\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, AutoConfig\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from IPython.display import HTML, display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap, torch, os\n",
    "from typing import Optional\n",
    "\n",
    "MODEL_PATH = \"../models/nlbse/\"\n",
    "config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_PATH, config=config)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "display_labels = [\"bug\", \"enhancement\", \"question\"]\n",
    "if getattr(model.config, \"id2label\", None):\n",
    "    raw = [model.config.id2label[i] for i in range(model.config.num_labels)]\n",
    "    labels = (\n",
    "        display_labels if set(raw) == {f\"LABEL_{i}\" for i in range(len(raw))} else raw\n",
    "    )\n",
    "else:\n",
    "    labels = display_labels\n",
    "assert len(labels) == model.config.num_labels, \"num_labels와 labels 길이가 다릅니다.\"\n",
    "\n",
    "\n",
    "def predict(texts):\n",
    "    enc = tokenizer(\n",
    "        list(texts), return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "    )\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "        probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "\n",
    "CSV_PATH = \"balanced_eval_set.csv\"\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"{CSV_PATH} file not found. Run the first cell to create it.\"\n",
    "    )\n",
    "df = pd.read_csv(CSV_PATH).reset_index(drop=True)\n",
    "\n",
    "text_col_title = \"issue_title\"\n",
    "text_col_body = \"issue_body\"\n",
    "gold_col = \"issue_label\"\n",
    "\n",
    "\n",
    "def build_text(row, title_col=text_col_title, body_col=text_col_body, max_chars=800):\n",
    "    title = str(row.get(title_col, \"\"))\n",
    "    body = str(row.get(body_col, \"\"))[:max_chars]\n",
    "    return (title + \"\\n\\n\" + body).strip()\n",
    "\n",
    "\n",
    "samples = [build_text(row) for _, row in df.iterrows()]\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=labels, random_state=42)\n",
    "\n",
    "for n, row in enumerate(df.itertuples(index=False)):\n",
    "    txt = samples[n]\n",
    "    probs = predict([txt])[0]\n",
    "    idx = int(probs.argmax())\n",
    "    predlab = labels[idx]\n",
    "    conf = float(probs[idx])\n",
    "\n",
    "    print(\n",
    "        f\"\\n[LIME {n:02d}] gold: {getattr(row, gold_col)} | pred: {predlab} (conf {conf:.2f})\"\n",
    "    )\n",
    "    exp = explainer.explain_instance(\n",
    "        txt, predict, labels=[idx], num_features=12, num_samples=600\n",
    "    )\n",
    "\n",
    "    html = exp.as_html(text=txt)\n",
    "    # display(HTML(html))\n",
    "    with open(f\"lime_{n:02d}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "\n",
    "CSS_FIX = \"\"\"\n",
    "<style>\n",
    "  html, body { margin: 8px; font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; }\n",
    "  .shap { position: relative; }\n",
    "  .shap .top { margin-bottom: 36px !important; position: relative; z-index: 1; }\n",
    "  .shap .text, .shap .inputs, .shap .labels { position: relative; z-index: 9999 !important; }\n",
    "  .shap .text span { line-height: 1.65 !important; } \n",
    "  svg { overflow: visible !important; }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "masker = shap.maskers.Text(\n",
    "    tokenizer=tokenizer, mask_token=(tokenizer.mask_token or \"[MASK]\")\n",
    ")\n",
    "shap_explainer = shap.Explainer(\n",
    "    predict, masker, output_names=labels, algorithm=\"partition\"\n",
    ")\n",
    "\n",
    "shap_values = shap_explainer(samples)\n",
    "print(\"\\nSHAP ready:\", len(shap_values), \"samples\")\n",
    "\n",
    "for i, sv in enumerate(shap_values):\n",
    "    txt = samples[i]\n",
    "    probs = predict([txt])[0]\n",
    "    cls = int(np.argmax(probs))\n",
    "\n",
    "    html_obj = shap.plots.text(sv[..., cls], display=False)\n",
    "    body = getattr(html_obj, \"data\", str(html_obj))\n",
    "    page = f\"<!doctype html><meta charset='utf-8'>{CSS_FIX}{body}\"\n",
    "    out = f\"shap_{i:02d}.html\"\n",
    "    with open(out, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(page)\n",
    "    print(f\"[SHAP {i:02d}] saved → {out} (pred={labels[cls]}, p={probs[cls]:.2f})\")\n",
    "mask_token_id = tokenizer.mask_token_id or tokenizer.convert_tokens_to_ids(\"[MASK]\")\n",
    "\n",
    "\n",
    "def predict_with_manual_mask(text, mask_indices, keep=False, max_length=512):\n",
    "    wp_tokens = tokenizer.tokenize(text)[: max_length - 2]\n",
    "    ids = tokenizer.convert_tokens_to_ids(wp_tokens)\n",
    "    input_ids = [tokenizer.cls_token_id] + ids + [tokenizer.sep_token_id]\n",
    "\n",
    "    if keep:\n",
    "        keep_set = set(mask_indices)\n",
    "        for t_idx in range(len(wp_tokens)):\n",
    "            pos = 1 + t_idx\n",
    "            if t_idx not in keep_set:\n",
    "                input_ids[pos] = mask_token_id\n",
    "    else:\n",
    "        for t_idx in mask_indices:\n",
    "            pos = 1 + t_idx\n",
    "            if 0 < pos < len(input_ids) - 1:\n",
    "                input_ids[pos] = mask_token_id\n",
    "\n",
    "    input_ids_tensor = torch.tensor([input_ids]).to(device)\n",
    "    attn = torch.ones_like(input_ids_tensor).to(device)\n",
    "    with torch.no_grad():\n",
    "        probs = torch.softmax(\n",
    "            model(input_ids=input_ids_tensor, attention_mask=attn).logits, dim=-1\n",
    "        )\n",
    "    return probs.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def topk_token_indices_for_class(sv, class_idx: int, k: int = 10, use_abs: bool = True):\n",
    "    vals = sv.values[:, class_idx]  # (num_tokens,)\n",
    "    order = np.argsort(-np.abs(vals)) if use_abs else np.argsort(-vals)\n",
    "    return order[: min(k, len(order))].tolist()\n",
    "\n",
    "\n",
    "def faithfulness_metrics(\n",
    "    text: str, sv, k: int = 10, use_abs: bool = True, class_idx: Optional[int] = None\n",
    "):\n",
    "    base_probs = predict([text])[0]\n",
    "    yhat = int(np.argmax(base_probs)) if class_idx is None else int(class_idx)\n",
    "    p_full = float(base_probs[yhat])\n",
    "\n",
    "    topk_idx = topk_token_indices_for_class(sv, yhat, k=k, use_abs=use_abs)\n",
    "\n",
    "    p_drop = float(predict_with_manual_mask(text, topk_idx, keep=False)[yhat])\n",
    "    compreh = p_full - p_drop\n",
    "\n",
    "    p_keep = float(predict_with_manual_mask(text, topk_idx, keep=True)[yhat])\n",
    "    suff = p_full - p_keep\n",
    "\n",
    "    return {\n",
    "        \"pred_class\": labels[yhat],\n",
    "        \"p_full\": p_full,\n",
    "        \"p_drop\": p_drop,\n",
    "        \"p_keep\": p_keep,\n",
    "        \"comprehensiveness\": compreh,\n",
    "        \"sufficiency\": suff,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_faithfulness(shap_values, samples, k: int = 10, use_abs: bool = True):\n",
    "    rows = []\n",
    "    for i, (sv, txt) in enumerate(zip(shap_values, samples)):\n",
    "        m = faithfulness_metrics(txt, sv, k=k, use_abs=use_abs)\n",
    "        m[\"i\"] = i\n",
    "        m[\"gold\"] = str(df.iloc[i][gold_col])\n",
    "        m[\"k\"] = k\n",
    "        m[\"comp_norm\"] = m[\"comprehensiveness\"] / (m[\"p_full\"] + 1e-8)\n",
    "        m[\"suff_abs\"] = abs(m[\"sufficiency\"])\n",
    "        rows.append(m)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "ks = [5, 10, 20]\n",
    "res = pd.concat(\n",
    "    [evaluate_faithfulness(shap_values, samples, k=k) for k in ks], ignore_index=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    res.groupby(\"k\")[[\"comprehensiveness\", \"comp_norm\", \"sufficiency\", \"suff_abs\"]]\n",
    "    .mean()\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "print(\n",
    "    res.groupby([\"k\", \"gold\"])[\n",
    "        [\"comprehensiveness\", \"comp_norm\", \"sufficiency\", \"suff_abs\"]\n",
    "    ]\n",
    "    .mean()\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "res.to_csv(\"faithfulness_results.csv\", index=False)\n",
    "print(\"\\nSaved: faithfulness_results.csv\")\n",
    "\n",
    "\n",
    "from PIL import Image, ImageChops\n",
    "import os, glob, math\n",
    "\n",
    "\n",
    "def trim_png(path, out=None, bg=(255, 255, 255), margin=4):\n",
    "    im = Image.open(path).convert(\"RGB\")\n",
    "    bg_im = Image.new(\"RGB\", im.size, bg)\n",
    "    diff = ImageChops.difference(im, bg_im)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox is None:\n",
    "\n",
    "        out = out or path\n",
    "        im.save(out)\n",
    "        return out\n",
    "    left, top, right, bottom = bbox\n",
    "    left = max(0, left - margin)\n",
    "    top = max(0, top - margin)\n",
    "    right = min(im.width, right + margin)\n",
    "    bottom = min(im.height, bottom + margin)\n",
    "    im2 = im.crop((left, top, right, bottom))\n",
    "\n",
    "    out = out or path\n",
    "    im2.save(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def stack_wide_png(\n",
    "    path, out=None, max_panel_width=1200, n_cols=None, overlap=32, pad=12, bg=\"white\"\n",
    "):\n",
    "\n",
    "    im = Image.open(path).convert(\"RGBA\")\n",
    "    W, H = im.size\n",
    "    if n_cols is None:\n",
    "        n_cols = max(2, math.ceil(W / max_panel_width))\n",
    "    col_w = math.ceil(W / n_cols)\n",
    "\n",
    "    panels = []\n",
    "    x0 = 0\n",
    "    for i in range(n_cols):\n",
    "        x1 = min(W, x0 + col_w + (overlap if i < n_cols - 1 else 0))\n",
    "        panels.append(im.crop((x0, 0, x1, H)))\n",
    "        x0 += col_w\n",
    "\n",
    "    newW = max(p.width for p in panels)\n",
    "    newH = sum(p.height for p in panels) + pad * (len(panels) - 1)\n",
    "    bg_rgba = (255, 255, 255, 0) if bg == \"transparent\" else (255, 255, 255, 255)\n",
    "    out_im = Image.new(\"RGBA\", (newW, newH), bg_rgba)\n",
    "\n",
    "    y = 0\n",
    "    for p in panels:\n",
    "        out_im.paste(p, (0, y))\n",
    "        y += p.height + pad\n",
    "\n",
    "    root, ext = os.path.splitext(path)\n",
    "    out = out or f\"{root}_stack{n_cols}{ext}\"\n",
    "    out_im.save(out)\n",
    "    print(\"saved:\", out)\n",
    "    return out\n",
    "\n",
    "\n",
    "for p in sorted(glob.glob(\"Fig/*.png\")):\n",
    "    trim_png(p, margin=6)\n",
    "\n",
    "for p in sorted(glob.glob(\"Fig/shap_*.png\")):\n",
    "    stacked = stack_wide_png(p, n_cols=2, max_panel_width=1400, overlap=36, pad=18)\n",
    "    trim_png(stacked, margin=4)\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "def _open_driver(width=2400, scale=1.8):\n",
    "    opts = Options()\n",
    "    opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--disable-gpu\")\n",
    "    opts.add_argument(\"--hide-scrollbars\")\n",
    "    opts.add_argument(f\"--window-size={width},1200\")\n",
    "    opts.add_argument(f\"--force-device-scale-factor={scale}\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service, options=opts)\n",
    "\n",
    "\n",
    "def _smart_lime_bbox(driver, container_sel=\"#explanation\", min_area=35000):\n",
    "    script = \"\"\"\n",
    "    const root = document.querySelector(arguments[0]) || document.body;\n",
    "    const minArea = arguments[1];\n",
    "    const els = root.querySelectorAll(\"*\");\n",
    "    const boxes = [];\n",
    "    for (const el of els) {\n",
    "      const cs = getComputedStyle(el);\n",
    "      if (cs.display==='none' || cs.visibility==='hidden' || parseFloat(cs.opacity)===0) continue;\n",
    "      const r = el.getBoundingClientRect();\n",
    "      if (r.width < 2 || r.height < 2) continue;\n",
    "      const tag = el.tagName.toLowerCase();\n",
    "      const area = r.width * r.height;\n",
    "      const cls = (el.className || \"\").toString();\n",
    "      const importantText = /highlight|text|raw|table|explanation|prob|prediction/i.test(cls);\n",
    "      const graphic = (tag==='svg' || tag==='canvas' || tag==='img');\n",
    "      if (graphic || importantText || area > minArea) {\n",
    "        boxes.push(r);\n",
    "      }\n",
    "    }\n",
    "    if (boxes.length === 0) return null;\n",
    "    let minX=Infinity, minY=Infinity, maxX=-Infinity, maxY=-Infinity;\n",
    "    for (const b of boxes){ minX=Math.min(minX,b.left); minY=Math.min(minY,b.top); maxX=Math.max(maxX,b.right); maxY=Math.max(maxY,b.bottom); }\n",
    "    return {x:minX, y:minY, w:maxX-minX, h:maxY-minY};\n",
    "    \"\"\"\n",
    "    return driver.execute_script(script, container_sel, min_area)\n",
    "\n",
    "\n",
    "def _fallback_union_bbox(driver):\n",
    "    return driver.execute_script(\n",
    "        \"\"\"\n",
    "      const els = document.body.querySelectorAll('*');\n",
    "      let minX=Infinity,minY=Infinity,maxX=-Infinity,maxY=-Infinity, found=false;\n",
    "      for(const el of els){\n",
    "        const cs = getComputedStyle(el);\n",
    "        if(cs.display==='none'||cs.visibility==='hidden'||parseFloat(cs.opacity)===0) continue;\n",
    "        const r = el.getBoundingClientRect();\n",
    "        if(r.width<2||r.height<2) continue;\n",
    "        minX=Math.min(minX,r.left); minY=Math.min(minY,r.top);\n",
    "        maxX=Math.max(maxX,r.right); maxY=Math.max(maxY,r.bottom);\n",
    "        found=true;\n",
    "      }\n",
    "      if(!found) return null;\n",
    "      return {x:minX,y:minY,w:maxX-minX,h:maxY-minY};\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def html_to_png_lime(\n",
    "    html_path,\n",
    "    out_png,\n",
    "    container_candidates=(\n",
    "        \"#explanation\",\n",
    "        \".explanation\",\n",
    "        \".explanation-container\",\n",
    "        \".lime\",\n",
    "        \".lime-container\",\n",
    "    ),\n",
    "    width=2400,\n",
    "    scale=1.8,\n",
    "    pad_x=28,\n",
    "    pad_y=16,\n",
    "    extra_h=800,\n",
    "):\n",
    "    abspath = os.path.abspath(html_path).replace(\"\\\\\", \"/\")\n",
    "    url = \"file:///\" + abspath\n",
    "    drv = _open_driver(width=width, scale=scale)\n",
    "    try:\n",
    "        drv.get(url)\n",
    "        time.sleep(0.6)\n",
    "\n",
    "        doc_h = drv.execute_script(\n",
    "            \"return Math.max(document.body.scrollHeight, document.documentElement.scrollHeight);\"\n",
    "        )\n",
    "        drv.set_window_size(width, int(doc_h) + extra_h)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        rect = None\n",
    "        for sel in container_candidates:\n",
    "            rect = _smart_lime_bbox(drv, sel, min_area=35000)\n",
    "            if rect:\n",
    "                break\n",
    "        if rect is None:\n",
    "            rect = _fallback_union_bbox(drv)\n",
    "            if rect is None:\n",
    "                raise RuntimeError(\"LIME: no visible content to capture.\")\n",
    "\n",
    "        dpr = drv.execute_script(\"return window.devicePixelRatio || 1;\")\n",
    "        left = int((rect[\"x\"] - pad_x) * dpr)\n",
    "        top = int((rect[\"y\"] - pad_y) * dpr)\n",
    "        right = int((rect[\"x\"] + rect[\"w\"] + pad_x) * dpr)\n",
    "        bottom = int((rect[\"y\"] + rect[\"h\"] + pad_y) * dpr)\n",
    "\n",
    "        png = drv.get_screenshot_as_png()\n",
    "        img = Image.open(io.BytesIO(png))\n",
    "        left = max(0, left)\n",
    "        top = max(0, top)\n",
    "        right = min(img.width, right)\n",
    "        bottom = min(img.height, bottom)\n",
    "        img.crop((left, top, right, bottom)).save(out_png)\n",
    "        print(f\"saved (LIME): {out_png}\")\n",
    "    finally:\n",
    "        drv.quit()\n",
    "\n",
    "\n",
    "for p in sorted(glob.glob(\"lime_*.html\")):\n",
    "    html_to_png_lime(\n",
    "        p, p.replace(\".html\", \".png\"), width=2400, scale=1.9, pad_x=36, pad_y=18\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ef32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== ALL-IN-ONE: LIME + SHAP + Faithfulness =====================\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AutoConfig\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from IPython.display import HTML, display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap, torch, os\n",
    "\n",
    "# ---- 0) 모델/토크나이저/라벨 ----------------------------------------------------\n",
    "MODEL_PATH = \"../models/nlbse/\"\n",
    "config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_PATH, config=config)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 사람이 읽는 라벨(모델 내부가 LABEL_0/1/2여도 표시용으로 교체)\n",
    "display_labels = [\"bug\", \"enhancement\", \"question\"]\n",
    "if getattr(model.config, \"id2label\", None):\n",
    "    raw = [model.config.id2label[i] for i in range(model.config.num_labels)]\n",
    "    labels = (\n",
    "        display_labels if set(raw) == {f\"LABEL_{i}\" for i in range(len(raw))} else raw\n",
    "    )\n",
    "else:\n",
    "    labels = display_labels\n",
    "assert len(labels) == model.config.num_labels, \"num_labels와 labels 길이가 다릅니다.\"\n",
    "\n",
    "\n",
    "def predict(texts):\n",
    "    enc = tokenizer(\n",
    "        list(texts), return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "    )\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "        probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "\n",
    "# ---- 1) 동일 샘플 로드(균형 샘플) -----------------------------------------------\n",
    "CSV_PATH = \"balanced_eval_set.csv\"\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"{CSV_PATH} 파일이 없습니다. 먼저 균형 샘플을 만들어 저장하세요.\"\n",
    "    )\n",
    "df = pd.read_csv(CSV_PATH).reset_index(drop=True)\n",
    "\n",
    "text_col_title = \"issue_title\"\n",
    "text_col_body = \"issue_body\"\n",
    "gold_col = \"issue_label\"\n",
    "\n",
    "\n",
    "def build_text(row, title_col=text_col_title, body_col=text_col_body, max_chars=800):\n",
    "    title = str(row.get(title_col, \"\"))\n",
    "    body = str(row.get(body_col, \"\"))[:max_chars]\n",
    "    return (title + \"\\n\\n\" + body).strip()\n",
    "\n",
    "\n",
    "samples = [build_text(row) for _, row in df.iterrows()]\n",
    "\n",
    "# ---- 2) LIME --------------------------------------------------------------------\n",
    "explainer = LimeTextExplainer(class_names=labels, random_state=42)\n",
    "\n",
    "for n, row in enumerate(df.itertuples(index=False)):\n",
    "    txt = samples[n]\n",
    "    probs = predict([txt])[0]\n",
    "    idx = int(probs.argmax())\n",
    "    predlab = labels[idx]\n",
    "    conf = float(probs[idx])\n",
    "\n",
    "    print(\n",
    "        f\"\\n[LIME {n:02d}] gold: {getattr(row, gold_col)} | pred: {predlab} (conf {conf:.2f})\"\n",
    "    )\n",
    "    exp = explainer.explain_instance(\n",
    "        txt, predict, labels=[idx], num_features=12, num_samples=600\n",
    "    )\n",
    "\n",
    "    html = exp.as_html(text=txt)\n",
    "    display(HTML(html))\n",
    "    with open(f\"lime_{n:02d}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "# ---- 3) SHAP (samples 동일) -----------------------------------------------------\n",
    "masker = shap.maskers.Text(\n",
    "    tokenizer=tokenizer, mask_token=(tokenizer.mask_token or \"[MASK]\")\n",
    ")\n",
    "shap_explainer = shap.Explainer(\n",
    "    predict, masker, output_names=labels, algorithm=\"partition\"\n",
    ")\n",
    "\n",
    "# 느리면 부분만: e.g., idx = list(range(30)); samples = [samples[i] for i in idx]; df = df.iloc[idx].reset_index(drop=True)\n",
    "shap_values = shap_explainer(samples)\n",
    "print(\"\\nSHAP ready:\", len(shap_values), \"samples\")\n",
    "\n",
    "# 저장(예측 클래스 기준) + 헤더에 gold/pred 표시\n",
    "for i, sv in enumerate(shap_values):\n",
    "    txt = samples[i]\n",
    "    probs = predict([txt])[0]\n",
    "    cls = int(np.argmax(probs))\n",
    "    predlab = labels[cls]\n",
    "    conf = float(probs[cls])\n",
    "    gold = str(df.iloc[i][gold_col])\n",
    "\n",
    "    html_obj = shap.plots.text(sv[..., cls], display=False)\n",
    "    body = getattr(html_obj, \"data\", str(html_obj))\n",
    "\n",
    "    with open(f\"shap_{i:02d}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\n",
    "            f\"<meta charset='utf-8'>\\n<h2>[{i:02d}] gold: {gold} | pred: {predlab} (conf {conf:.2f})</h2>\\n\"\n",
    "            + body\n",
    "        )\n",
    "    print(\n",
    "        f\"[SHAP {i:02d}] gold={gold} | pred={predlab} (conf={conf:.2f}) → shap_{i:02d}.html\"\n",
    "    )\n",
    "\n",
    "# ---- 4) Faithfulness (Comprehensiveness / Sufficiency) --------------------------\n",
    "mask_token_id = tokenizer.mask_token_id or tokenizer.convert_tokens_to_ids(\"[MASK]\")\n",
    "\n",
    "\n",
    "def predict_with_manual_mask(text, mask_indices, keep=False, max_length=512):\n",
    "    # WordPiece 토큰을 선택적으로 [MASK] 처리 후 모델 확률 반환\n",
    "    wp_tokens = tokenizer.tokenize(text)[: max_length - 2]\n",
    "    ids = tokenizer.convert_tokens_to_ids(wp_tokens)\n",
    "    input_ids = [tokenizer.cls_token_id] + ids + [tokenizer.sep_token_id]\n",
    "\n",
    "    if keep:\n",
    "        keep_set = set(mask_indices)\n",
    "        for t_idx in range(len(wp_tokens)):\n",
    "            pos = 1 + t_idx\n",
    "            if t_idx not in keep_set:\n",
    "                input_ids[pos] = mask_token_id\n",
    "    else:\n",
    "        for t_idx in mask_indices:\n",
    "            pos = 1 + t_idx\n",
    "            if 0 < pos < len(input_ids) - 1:\n",
    "                input_ids[pos] = mask_token_id\n",
    "\n",
    "    input_ids_tensor = torch.tensor([input_ids]).to(device)\n",
    "    attn = torch.ones_like(input_ids_tensor).to(device)\n",
    "    with torch.no_grad():\n",
    "        probs = torch.softmax(\n",
    "            model(input_ids=input_ids_tensor, attention_mask=attn).logits, dim=-1\n",
    "        )\n",
    "    return probs.squeeze(0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c08898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6) Post-process: trim whitespace + split-wide-and-stack ====================\n",
    "from PIL import Image, ImageChops\n",
    "import os, glob, math\n",
    "\n",
    "\n",
    "def trim_png(path, out=None, bg=(255, 255, 255), margin=4):\n",
    "    \"\"\"\n",
    "    PNG 가장자리의 불필요한 흰 여백을 자동으로 잘라냅니다.\n",
    "    margin: 잘라낸 뒤 남겨둘 최소 여백(px)\n",
    "    \"\"\"\n",
    "    im = Image.open(path).convert(\"RGB\")\n",
    "    bg_im = Image.new(\"RGB\", im.size, bg)\n",
    "    diff = ImageChops.difference(im, bg_im)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox is None:\n",
    "        # 트리밍할 게 없으면 그대로 저장\n",
    "        out = out or path\n",
    "        im.save(out)\n",
    "        return out\n",
    "\n",
    "    # 마진을 살짝 더 남김\n",
    "    left, top, right, bottom = bbox\n",
    "    left = max(0, left - margin)\n",
    "    top = max(0, top - margin)\n",
    "    right = min(im.width, right + margin)\n",
    "    bottom = min(im.height, bottom + margin)\n",
    "    im2 = im.crop((left, top, right, bottom))\n",
    "\n",
    "    out = out or path\n",
    "    im2.save(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def stack_wide_png(\n",
    "    path, out=None, max_panel_width=1200, n_cols=None, overlap=32, pad=12, bg=\"white\"\n",
    "):\n",
    "    \"\"\"\n",
    "    가로로 긴 PNG를 좌→우로 2~3등분하여, 위→아래로 이어붙인 PNG 생성.\n",
    "\n",
    "    - max_panel_width: Overleaf 한 줄에 들어가길 원하는 '패널 한 장의 최대 폭'\n",
    "    - n_cols: None이면 원본 폭으로 자동 계산(보통 SHAP는 2, 아주 길면 3 권장)\n",
    "    - overlap: 잘리는 경계에 좌우로 겹침을 주어 단어가 반 잘리는 문제 완화\n",
    "    - pad: 패널들 사이 세로 간격(px)\n",
    "    \"\"\"\n",
    "    im = Image.open(path).convert(\"RGBA\")\n",
    "    W, H = im.size\n",
    "    if n_cols is None:\n",
    "        n_cols = max(2, math.ceil(W / max_panel_width))\n",
    "    col_w = math.ceil(W / n_cols)\n",
    "\n",
    "    panels = []\n",
    "    x0 = 0\n",
    "    for i in range(n_cols):\n",
    "        x1 = min(W, x0 + col_w + (overlap if i < n_cols - 1 else 0))\n",
    "        panels.append(im.crop((x0, 0, x1, H)))\n",
    "        x0 += col_w\n",
    "\n",
    "    newW = max(p.width for p in panels)\n",
    "    newH = sum(p.height for p in panels) + pad * (len(panels) - 1)\n",
    "    bg_rgba = (255, 255, 255, 0) if bg == \"transparent\" else (255, 255, 255, 255)\n",
    "    out_im = Image.new(\"RGBA\", (newW, newH), bg_rgba)\n",
    "\n",
    "    y = 0\n",
    "    for p in panels:\n",
    "        out_im.paste(p, (0, y))\n",
    "        y += p.height + pad\n",
    "\n",
    "    root, ext = os.path.splitext(path)\n",
    "    out = out or f\"{root}_stack{n_cols}{ext}\"\n",
    "    out_im.save(out)\n",
    "    print(\"saved:\", out)\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- 6.1 모든 PNG 여백 트리밍 ---\n",
    "for p in sorted(glob.glob(\"Fig/*.png\")):\n",
    "    trim_png(p, margin=6)\n",
    "\n",
    "# --- 6.2 SHAP 그림은 2등분(아주 길면 3등분)해서 세로 스택 버전 생성 ---\n",
    "for p in sorted(glob.glob(\"Fig/shap_*.png\")):\n",
    "    # 필요 시 n_cols=3 로 바꾸면 더 짧은 패널을 얻을 수 있습니다.\n",
    "    stacked = stack_wide_png(p, n_cols=2, max_panel_width=1400, overlap=36, pad=18)\n",
    "    # 스택 결과도 한번 더 트리밍(경계 여백 제거)\n",
    "    trim_png(stacked, margin=4)\n",
    "\n",
    "# (선택) LIME도 가로가 길면 동일 처리\n",
    "# for p in sorted(glob.glob(\"Fig/lime_*.png\")):\n",
    "#     stacked = stack_wide_png(p, n_cols=2, max_panel_width=1400, overlap=36, pad=18)\n",
    "#     trim_png(stacked, margin=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5801b42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 31it [01:04,  2.37s/it]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: multiclass_html\\sample_00_multiclass.html\n",
      "saved: multiclass_html\\sample_01_multiclass.html\n",
      "saved: multiclass_html\\sample_02_multiclass.html\n",
      "saved: multiclass_html\\sample_03_multiclass.html\n",
      "saved: multiclass_html\\sample_04_multiclass.html\n",
      "saved: multiclass_html\\sample_05_multiclass.html\n",
      "saved: multiclass_html\\sample_06_multiclass.html\n",
      "saved: multiclass_html\\sample_07_multiclass.html\n",
      "saved: multiclass_html\\sample_08_multiclass.html\n",
      "saved: multiclass_html\\sample_09_multiclass.html\n",
      "saved: multiclass_html\\sample_10_multiclass.html\n",
      "saved: multiclass_html\\sample_11_multiclass.html\n",
      "saved: multiclass_html\\sample_12_multiclass.html\n",
      "saved: multiclass_html\\sample_13_multiclass.html\n",
      "saved: multiclass_html\\sample_14_multiclass.html\n",
      "saved: multiclass_html\\sample_15_multiclass.html\n",
      "saved: multiclass_html\\sample_16_multiclass.html\n",
      "saved: multiclass_html\\sample_17_multiclass.html\n",
      "saved: multiclass_html\\sample_18_multiclass.html\n",
      "saved: multiclass_html\\sample_19_multiclass.html\n",
      "saved: multiclass_html\\sample_20_multiclass.html\n",
      "saved: multiclass_html\\sample_21_multiclass.html\n",
      "saved: multiclass_html\\sample_22_multiclass.html\n",
      "saved: multiclass_html\\sample_23_multiclass.html\n",
      "saved: multiclass_html\\sample_24_multiclass.html\n",
      "saved: multiclass_html\\sample_25_multiclass.html\n",
      "saved: multiclass_html\\sample_26_multiclass.html\n",
      "saved: multiclass_html\\sample_27_multiclass.html\n",
      "saved: multiclass_html\\sample_28_multiclass.html\n",
      "saved: multiclass_html\\sample_29_multiclass.html\n"
     ]
    }
   ],
   "source": [
    "# ================= MULTI-CLASS SHAP (LIME-Style) =================\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AutoConfig\n",
    "import torch, numpy as np, pandas as pd, shap, os\n",
    "\n",
    "# ---------- 0) 모델/토크나이저/라벨 ----------\n",
    "MODEL_PATH = \"../models/nlbse/\"\n",
    "config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_PATH, config=config)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "display_labels = [\"bug\", \"enhancement\", \"question\"]\n",
    "if getattr(model.config, \"id2label\", None):\n",
    "    raw = [model.config.id2label[i] for i in range(model.config.num_labels)]\n",
    "    labels = (\n",
    "        display_labels if set(raw) == {f\"LABEL_{i}\" for i in range(len(raw))} else raw\n",
    "    )\n",
    "else:\n",
    "    labels = display_labels\n",
    "assert len(labels) == model.config.num_labels, \"labels 길이와 num_labels가 다름\"\n",
    "\n",
    "\n",
    "def predict(texts):\n",
    "    enc = tokenizer(\n",
    "        list(texts), return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "    )\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        probs = torch.softmax(model(**enc).logits, dim=-1).cpu().numpy()\n",
    "    return probs  # (N, C)\n",
    "\n",
    "\n",
    "# ---------- 1) 동일 샘플 로드 ----------\n",
    "CSV_PATH = \"balanced_eval_set.csv\"\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(\"balanced_eval_set.csv 가 없습니다.\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH).reset_index(drop=True)\n",
    "text_col_title = \"issue_title\"\n",
    "text_col_body = \"issue_body\"\n",
    "gold_col = \"issue_label\"\n",
    "\n",
    "\n",
    "def build_text(row, title_col=text_col_title, body_col=text_col_body, max_chars=800):\n",
    "    title = str(row.get(title_col, \"\"))\n",
    "    body = str(row.get(body_col, \"\"))[:max_chars]\n",
    "    return (title + \"\\n\\n\" + body).strip()\n",
    "\n",
    "\n",
    "samples = [build_text(row) for _, row in df.iterrows()]\n",
    "\n",
    "# ---------- 2) SHAP 계산 ----------\n",
    "masker = shap.maskers.Text(\n",
    "    tokenizer=tokenizer, mask_token=(tokenizer.mask_token or \"[MASK]\")\n",
    ")\n",
    "explainer = shap.Explainer(predict, masker, output_names=labels, algorithm=\"partition\")\n",
    "shap_values = explainer(\n",
    "    samples\n",
    ")  # len == N, 각 sv.values.shape == (num_tokens, num_classes)\n",
    "\n",
    "\n",
    "# ---------- 3) LIME-스타일 토큰만 색칠하는 HTML 유틸 ----------\n",
    "def _needs_space(tok):\n",
    "    # WordPiece 접두 '##'는 앞 공백 X, 일반 토큰은 공백\n",
    "    if tok.startswith(\"##\"):\n",
    "        return False\n",
    "    # 붙여 쓰는 구두점\n",
    "    if tok in {\".\", \",\", \"!\", \"?\", \":\", \";\", \")\", \"]\", \"}\", \"'\", '\"'}:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def _clean_token(tok):\n",
    "    return tok[2:] if tok.startswith(\"##\") else tok\n",
    "\n",
    "\n",
    "def tokens_html_for_class(sv, class_idx, topk=None):\n",
    "    \"\"\"\n",
    "    sv: shap.Explanation (sv.values.shape == [T, C])\n",
    "    class_idx: 시각화할 클래스 인덱스\n",
    "    topk: 상위 k 토큰만 강조(나머지는 연한 회색). None이면 전체 강조\n",
    "    return: <div>...</div> (토큰만 들어있는 HTML 조각)\n",
    "    \"\"\"\n",
    "    import html as _html\n",
    "\n",
    "    tokens = list(sv.data)\n",
    "    vals = np.array(sv.values[:, class_idx], dtype=float)\n",
    "\n",
    "    if topk is not None and topk < len(vals):\n",
    "        keep = np.argsort(-np.abs(vals))[:topk]\n",
    "        mask = np.zeros_like(vals, dtype=bool)\n",
    "        mask[keep] = True\n",
    "    else:\n",
    "        mask = np.ones_like(vals, dtype=bool)\n",
    "\n",
    "    max_abs = float(np.max(np.abs(vals)) + 1e-12)\n",
    "    spans = []\n",
    "    for t, v, keep_it in zip(tokens, vals, mask):\n",
    "        space = \" \" if _needs_space(t) and len(spans) > 0 else \"\"\n",
    "        tok = _clean_token(t)\n",
    "        tok = _html.escape(tok)\n",
    "\n",
    "        if keep_it:\n",
    "            alpha = 0.15 + 0.85 * (abs(v) / max_abs)\n",
    "            color = (\n",
    "                (\"rgba(255,0,0,%f)\" % alpha)\n",
    "                if v >= 0\n",
    "                else (\"rgba(0,102,255,%f)\" % alpha)\n",
    "            )\n",
    "        else:\n",
    "            color = \"rgba(128,128,128,0.12)\"  # 비강조\n",
    "\n",
    "        spans.append(\n",
    "            f\"{space}<span style='background:{color}; padding:2px 2px; border-radius:3px'>{tok}</span>\"\n",
    "        )\n",
    "\n",
    "    return \"<div>\" + \"\".join(spans) + \"</div>\"\n",
    "\n",
    "\n",
    "# ---------- 4) 멀티클래스 한 페이지로 저장 ----------\n",
    "TOPK = 20  # 상위 20개만 진하게(원하면 None으로 전체 강조)\n",
    "os.makedirs(\"multiclass_html\", exist_ok=True)\n",
    "\n",
    "for i, sv in enumerate(shap_values):\n",
    "    probs = predict([samples[i]])[0]  # (C,)\n",
    "    order = probs.argsort()[::-1]  # 확률 내림차순\n",
    "    gold = str(df.iloc[i][gold_col])\n",
    "    header = (\n",
    "        \"<meta charset='utf-8'>\"\n",
    "        \"<style>body{font-family:-apple-system,Segoe UI,Roboto,Arial;line-height:1.8;font-size:16px}\"\n",
    "        \".cl{margin:12px 0 22px 0;padding:8px 12px;border:1px solid #eee;border-radius:8px}\"\n",
    "        \".lab{font-weight:600;margin-bottom:6px}\"\n",
    "        \".legend{margin:6px 0 12px 0;font-size:14px}\"\n",
    "        \"</style>\"\n",
    "        f\"<h2>[{i:02d}] gold: {gold} | pred: {labels[int(order[0])]} \"\n",
    "        f\"(p={probs[int(order[0])]:.2f})</h2>\"\n",
    "        \"<div class='legend'>\"\n",
    "        \"<span style='display:inline-block;width:12px;height:12px;background:rgba(255,0,0,0.6);margin-right:6px;vertical-align:middle'></span>\"\n",
    "        \"positive for class&nbsp;&nbsp;\"\n",
    "        \"<span style='display:inline-block;width:12px;height:12px;background:rgba(0,102,255,0.6);margin:0 6px 0 16px;vertical-align:middle'></span>\"\n",
    "        \"negative\"\n",
    "        \"</div>\"\n",
    "        \"<div style='margin:6px 0 12px 0'>\"\n",
    "        + \" | \".join(f\"{labels[c]}: {probs[c]:.2f}\" for c in order)\n",
    "        + \"</div>\"\n",
    "    )\n",
    "\n",
    "    # 세 클래스 모두 섹션으로 추가 (확률 높은 순으로 정렬)\n",
    "    sections = []\n",
    "    for c in order:\n",
    "        sec = (\n",
    "            f\"<div class='cl'>\"\n",
    "            f\"<div class='lab'>{labels[int(c)]} (p={probs[int(c)]:.2f})</div>\"\n",
    "            f\"{tokens_html_for_class(sv, int(c), topk=TOPK)}\"\n",
    "            f\"</div>\"\n",
    "        )\n",
    "        sections.append(sec)\n",
    "\n",
    "    page = header + \"\\n\".join(sections)\n",
    "    out = os.path.join(\"multiclass_html\", f\"sample_{i:02d}_multiclass.html\")\n",
    "    with open(out, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(page)\n",
    "    print(f\"saved: {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b5a29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved shap_lime_00.html (class=bug)\n",
      "saved shap_lime_01.html (class=bug)\n",
      "saved shap_lime_02.html (class=bug)\n",
      "saved shap_lime_03.html (class=bug)\n",
      "saved shap_lime_04.html (class=bug)\n",
      "saved shap_lime_05.html (class=bug)\n",
      "saved shap_lime_06.html (class=bug)\n",
      "saved shap_lime_07.html (class=bug)\n",
      "saved shap_lime_08.html (class=question)\n",
      "saved shap_lime_09.html (class=bug)\n",
      "saved shap_lime_10.html (class=enhancement)\n",
      "saved shap_lime_11.html (class=enhancement)\n",
      "saved shap_lime_12.html (class=enhancement)\n",
      "saved shap_lime_13.html (class=enhancement)\n",
      "saved shap_lime_14.html (class=enhancement)\n",
      "saved shap_lime_15.html (class=enhancement)\n",
      "saved shap_lime_16.html (class=enhancement)\n",
      "saved shap_lime_17.html (class=enhancement)\n",
      "saved shap_lime_18.html (class=bug)\n",
      "saved shap_lime_19.html (class=enhancement)\n",
      "saved shap_lime_20.html (class=question)\n",
      "saved shap_lime_21.html (class=bug)\n",
      "saved shap_lime_22.html (class=bug)\n",
      "saved shap_lime_23.html (class=enhancement)\n",
      "saved shap_lime_24.html (class=bug)\n",
      "saved shap_lime_25.html (class=question)\n",
      "saved shap_lime_26.html (class=question)\n",
      "saved shap_lime_27.html (class=enhancement)\n",
      "saved shap_lime_28.html (class=question)\n",
      "saved shap_lime_29.html (class=question)\n"
     ]
    }
   ],
   "source": [
    "# ===== SHAP 결과를 LIME 스타일(토큰만 색 하이라이트)로 저장 =====\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _needs_space(tok: str):\n",
    "    # BERT WordPiece: '##'로 붙는 토큰은 앞 공백 X, 일반 토큰은 앞에 공백\n",
    "    if tok.startswith(\"##\"):\n",
    "        return False\n",
    "    # 구두점은 앞 공백 없이 붙이기\n",
    "    if tok in {\".\", \",\", \"!\", \"?\", \":\", \";\", \")\", \"]\", \"}\", \"'\", '\"'}:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def _clean_token(tok: str):\n",
    "    # BERT WordPiece '##ing' -> 'ing'\n",
    "    return tok[2:] if tok.startswith(\"##\") else tok\n",
    "\n",
    "\n",
    "def shap_as_lime_html(sv, class_idx, header=\"\", topk=None):\n",
    "    \"\"\"\n",
    "    sv: shap.Explanation (sv.values.shape == [num_tokens, num_classes])\n",
    "    class_idx: 시각화할 클래스 인덱스\n",
    "    topk: 상위 k개 토큰만 색칠(선택). None이면 전부 색칠\n",
    "    \"\"\"\n",
    "    tokens = list(sv.data)\n",
    "    vals = np.array(sv.values[:, class_idx], dtype=float)\n",
    "\n",
    "    # 상위 k만 하이라이트하고 나머지는 연한 회색으로 처리(선택)\n",
    "    if topk is not None and topk < len(vals):\n",
    "        keep = np.argsort(-np.abs(vals))[:topk]\n",
    "        mask = np.zeros_like(vals, dtype=bool)\n",
    "        mask[keep] = True\n",
    "    else:\n",
    "        mask = np.ones_like(vals, dtype=bool)\n",
    "\n",
    "    max_abs = np.max(np.abs(vals)) + 1e-12\n",
    "\n",
    "    html_tokens = []\n",
    "    for t, v, keep_it in zip(tokens, vals, mask):\n",
    "        space = \" \" if _needs_space(t) and len(html_tokens) > 0 else \"\"\n",
    "        tok = _clean_token(t)\n",
    "\n",
    "        if keep_it:\n",
    "            # 빨강=해당 클래스에 +기여, 파랑=−기여 (진할수록 영향 큼)\n",
    "            alpha = 0.15 + 0.85 * (abs(v) / max_abs)\n",
    "            color = f\"rgba(255,0,0,{alpha})\" if v >= 0 else f\"rgba(0,102,255,{alpha})\"\n",
    "        else:\n",
    "            color = \"rgba(128,128,128,0.15)\"  # 연한 회색(비강조)\n",
    "\n",
    "        html_tokens.append(\n",
    "            f\"{space}<span style='background:{color}; padding:2px 2px; border-radius:3px'>{tok}</span>\"\n",
    "        )\n",
    "\n",
    "    # 페이지 구성\n",
    "    legend = (\n",
    "        \"<div style='margin:6px 0 12px 0;font-size:14px'>\"\n",
    "        \"<span style='display:inline-block;width:12px;height:12px;background:rgba(255,0,0,0.6);margin-right:6px;vertical-align:middle'></span>\"\n",
    "        \"positive for class &nbsp;&nbsp;\"\n",
    "        \"<span style='display:inline-block;width:12px;height:12px;background:rgba(0,102,255,0.6);margin:0 6px 0 16px;vertical-align:middle'></span>\"\n",
    "        \"negative\"\n",
    "        \"</div>\"\n",
    "    )\n",
    "    page = (\n",
    "        \"<meta charset='utf-8'>\"\n",
    "        \"<style>body{font-family:-apple-system,Segoe UI,Roboto,Arial;line-height:1.8;font-size:16px}</style>\"\n",
    "        f\"<h2 style='margin:6px 0 6px'>{header}</h2>\"\n",
    "        f\"{legend}\"\n",
    "        f\"<div>{''.join(html_tokens)}</div>\"\n",
    "    )\n",
    "    return page\n",
    "\n",
    "\n",
    "# 예: 각 샘플을 예측 클래스 기준으로 LIME 스타일 저장 (상위 20개만 강조)\n",
    "for i, sv in enumerate(shap_values):\n",
    "    probs = predict([samples[i]])[0]\n",
    "    cls = int(np.argmax(probs))\n",
    "    predlab = labels[cls]\n",
    "    conf = float(probs[cls])\n",
    "    gold = str(df.iloc[i][gold_col])\n",
    "\n",
    "    html = shap_as_lime_html(\n",
    "        sv,\n",
    "        class_idx=cls,\n",
    "        header=f\"[{i:02d}] gold: {gold} | pred: {predlab} (conf {conf:.2f})\",\n",
    "        topk=20,  # ← 원하면 None으로 바꿔 전체 토큰 강조\n",
    "    )\n",
    "    with open(f\"shap_lime_{i:02d}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "    print(f\"saved shap_lime_{i:02d}.html (class={predlab})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== LIME ↑ / SHAP ↓ 패널 그리기 ==================\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "# ---------- 0) 유틸: WordPiece -> 단어로 합치기 ----------\n",
    "def merge_wordpiece(tokens, scores):\n",
    "    words, vals = [], []\n",
    "    cur, cur_v = \"\", 0.0\n",
    "    for t, v in zip(tokens, scores):\n",
    "        if t.startswith(\"##\"):\n",
    "            cur += t[2:]\n",
    "            cur_v += v\n",
    "        else:\n",
    "            if cur:\n",
    "                words.append(cur)\n",
    "                vals.append(cur_v)\n",
    "            cur, cur_v = t, v\n",
    "    if cur:\n",
    "        words.append(cur)\n",
    "        vals.append(cur_v)\n",
    "    return words, vals  # 동일 길이\n",
    "\n",
    "\n",
    "def topk_pairs_from_dict(d, k=10):\n",
    "    return sorted(d.items(), key=lambda x: -abs(x[1]))[:k]\n",
    "\n",
    "\n",
    "# ---------- 1) LIME 특징 상위 K 추출 ----------\n",
    "def lime_topk(text, lime_explainer, cls_idx, k=10, num_samples=600):\n",
    "    exp = lime_explainer.explain_instance(\n",
    "        text,\n",
    "        predict,\n",
    "        labels=[cls_idx],\n",
    "        num_features=max(k, 50),\n",
    "        num_samples=num_samples,\n",
    "    )\n",
    "    feat_list = exp.as_list(label=cls_idx)  # [('token', weight), ...]\n",
    "    # 일부 토큰이 중복될 수 있어 dict로 합산\n",
    "    agg = {}\n",
    "    for w, v in feat_list:\n",
    "        agg[w] = agg.get(w, 0.0) + v\n",
    "    topk = topk_pairs_from_dict(agg, k)\n",
    "    return topk, exp.score  # ([(token, weight), ...], local fidelity R^2)\n",
    "\n",
    "\n",
    "# ---------- 2) SHAP 특징 상위 K 추출 ----------\n",
    "def shap_topk(sv, cls_idx, k=10):\n",
    "    toks = list(sv.data)\n",
    "    vals = sv.values[:, cls_idx]\n",
    "    words, scores = merge_wordpiece(toks, vals)\n",
    "    d = {}\n",
    "    for w, v in zip(words, scores):\n",
    "        d[w] = d.get(w, 0.0) + v\n",
    "    return topk_pairs_from_dict(d, k)\n",
    "\n",
    "\n",
    "# ---------- 3) 간단 메트릭(근사치) ----------\n",
    "def agreement_spearman_abs(dict_a, dict_b):\n",
    "    # 공통 단어에 대해 |score| 스피어만 상관\n",
    "    common = list(set(dict_a.keys()) & set(dict_b.keys()))\n",
    "    if len(common) < 3:\n",
    "        return np.nan\n",
    "    a = [abs(dict_a[w]) for w in common]\n",
    "    b = [abs(dict_b[w]) for w in common]\n",
    "    rho, _ = spearmanr(a, b)\n",
    "    return float(rho)\n",
    "\n",
    "\n",
    "def jaccard_at_k(dict_a, dict_b, k=10):\n",
    "    A = set([w for w, _ in topk_pairs_from_dict(dict_a, k)])\n",
    "    B = set([w for w, _ in topk_pairs_from_dict(dict_b, k)])\n",
    "    if not (A or B):\n",
    "        return np.nan\n",
    "    return len(A & B) / len(A | B)\n",
    "\n",
    "\n",
    "def prescriptivity_like(text, ranked_words, k=10):\n",
    "    \"\"\"\n",
    "    '상위 k만 남기고' 확률 유지 정도를 간단 수치로(높을수록 '충분').\n",
    "    실제 Prescriptivity의 대체 지표: p_keep / p_full\n",
    "    -> 1에 가까울수록 상위 k만으로 충분.\n",
    "    ranked_words: [('word', score), ...]\n",
    "    주의: WordPiece 맵핑 복잡성 때문에 여기선 상위 k '단어'만 남긴\n",
    "    텍스트 서브스트링 기반의 매우 보수적 근사(간단히 삭제/유지) 대신,\n",
    "    shap 기반 prescriptivity를 사용하는 것을 권장.\n",
    "    \"\"\"\n",
    "    # 안전하게 shap 기반 prescriptivity로 대체:\n",
    "    base = predict([text])[0]\n",
    "    y = int(base.argmax())\n",
    "    p0 = float(base[y])\n",
    "    return np.nan, p0  # 필요 시 직접 구현/대체\n",
    "\n",
    "\n",
    "# ---------- 4) 메트릭 패널을 위한 dict 형태로 수집 ----------\n",
    "def build_metrics_for_lime(text, lime_dict, shap_dict, lime_score):\n",
    "    # Reit. Similarity: 간단히 LIME을 5회 반복해 Jaccard@k 평균 (가벼운 근사)\n",
    "    # 계산 비용이 크면 skip하고 NaN 대입해도 됨.\n",
    "    k = min(10, len(lime_dict))\n",
    "    # 여기선 반복 실행 없이 상호 Jaccard를 재사용하거나 NaN 처리\n",
    "    reit_mean = np.nan\n",
    "    reit_std = np.nan\n",
    "\n",
    "    # Local Concordance: LIME vs SHAP 중요도 일치(스피어만)\n",
    "    lc = agreement_spearman_abs(lime_dict, shap_dict)\n",
    "\n",
    "    # Local Fidelity: LIME exp.score (R^2)\n",
    "    lf = float(lime_score)\n",
    "\n",
    "    # Prescriptivity: 간단 대체(여기선 NaN)\n",
    "    pres, _ = prescriptivity_like(text, topk_pairs_from_dict(lime_dict, k))\n",
    "    return {\n",
    "        \"Reit. Similarity\": (reit_mean, reit_std),\n",
    "        \"Local Concordance\": (lc, 0.0),\n",
    "        \"Local Fidelity\": (lf, 0.0),\n",
    "        \"Prescriptivity\": (pres, 0.0),\n",
    "    }\n",
    "\n",
    "\n",
    "def build_metrics_for_shap(text, shap_dict):\n",
    "    # SHAP은 결정적이라 Reit=1.0로 간주(근사)\n",
    "    reit = (1.0, 0.0)\n",
    "    # Local Concordance: SHAP 내부 일관성 지표가 없어 NaN\n",
    "    lc = (np.nan, 0.0)\n",
    "    # Local Fidelity: base + sum(phi) 근사 → 확률과의 절대오차로 근사 (간단)\n",
    "    base = predict([text])[0]\n",
    "    y = int(base.argmax())\n",
    "    p0 = float(base[y])\n",
    "    # fidelity를 1-|오차|로 근사(매우 보수적)\n",
    "    approx = p0  # 간단 대체\n",
    "    lf = (max(0.0, 1.0 - abs(p0 - approx)), 0.0)\n",
    "    # Prescriptivity: shap 상위 k만 남겼을 때 p_keep / p_full (정의 맞춤)\n",
    "    # -> 필요시 너의 predict_with_manual_mask + shap 토큰 인덱스로 정확 계산 권장\n",
    "    pres = (np.nan, 0.0)\n",
    "    return {\n",
    "        \"Reit. Similarity\": reit,\n",
    "        \"Local Concordance\": lc,\n",
    "        \"Local Fidelity\": lf,\n",
    "        \"Prescriptivity\": pres,\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------- 5) 그림 그리기 ----------\n",
    "def _draw_prob_bar(ax, probs, cls_names):\n",
    "    ax.barh(range(len(probs)), probs)\n",
    "    ax.set_yticks(range(len(probs)))\n",
    "    ax.set_yticklabels(cls_names)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(\"Prediction probabilities\")\n",
    "\n",
    "\n",
    "def _draw_feature_table(ax, pairs, title=\"Feature  Value\"):\n",
    "    # pairs: [('token', score), ...]\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(title, loc=\"left\")\n",
    "    rows = len(pairs)\n",
    "    y = 1.0\n",
    "    dy = 1.0 / (rows + 1e-9)\n",
    "    for w, v in pairs:\n",
    "        y -= dy\n",
    "        ax.text(0.0, y, str(w), va=\"center\", ha=\"left\")\n",
    "        ax.text(0.95, y, f\"{v:.2f}\", va=\"center\", ha=\"right\")\n",
    "\n",
    "\n",
    "def _draw_metrics(ax, metrics_dict):\n",
    "    \"\"\"\n",
    "    metrics_dict: {name: (mean, std)}\n",
    "    \"\"\"\n",
    "    names = list(metrics_dict.keys())\n",
    "    vals = [metrics_dict[n][0] for n in names]\n",
    "    stds = [metrics_dict[n][1] for n in names]\n",
    "    ax.scatter(vals, range(len(names)))\n",
    "    # 오차막대(±std)\n",
    "    for yi, (m, s) in enumerate(zip(vals, stds)):\n",
    "        if np.isnan(m):\n",
    "            continue\n",
    "        ax.hlines(yi, max(0, m - s), min(1, m + s))\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_yticks(range(len(names)))\n",
    "    ax.set_yticklabels(names)\n",
    "    ax.set_xlabel(\"value\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(True, axis=\"x\", alpha=0.3)\n",
    "\n",
    "\n",
    "def plot_lime_shap_panel(i=0, K=8, lime_num_samples=600, savepath=None):\n",
    "    text = samples[i]\n",
    "    probs = predict([text])[0]\n",
    "    pred = int(np.argmax(probs))\n",
    "    gold = str(df.iloc[i][gold_col])\n",
    "\n",
    "    # LIME 상위 K\n",
    "    lime_pairs, lime_score = lime_topk(\n",
    "        text, explainer, pred, k=K, num_samples=lime_num_samples\n",
    "    )\n",
    "    lime_dict = {w: v for w, v in lime_pairs}\n",
    "\n",
    "    # SHAP 상위 K (이미 계산된 shap_values 사용)\n",
    "    sv = shap_values[i]\n",
    "    shap_pairs = shap_topk(sv, pred, k=K)\n",
    "    shap_dict = {w: v for w, v in shap_pairs}\n",
    "\n",
    "    # 메트릭(근사) 구성\n",
    "    m_lime = build_metrics_for_lime(text, lime_dict, shap_dict, lime_score)\n",
    "    m_shap = build_metrics_for_shap(text, shap_dict)\n",
    "\n",
    "    # --- 레이아웃 ---\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = GridSpec(\n",
    "        4, 2, height_ratios=[1, 2, 1, 2], width_ratios=[1.2, 1], hspace=0.5, wspace=0.35\n",
    "    )\n",
    "\n",
    "    # (A) LIME 상단: 확률 + 특징 테이블\n",
    "    ax_prob = fig.add_subplot(gs[0, :])\n",
    "    _draw_prob_bar(ax_prob, probs, labels)\n",
    "    ax_prob.set_title(\n",
    "        f\"K={K}   gold: {gold} | pred: {labels[pred]} (p={probs[pred]:.2f})\"\n",
    "    )\n",
    "\n",
    "    ax_lime_feat = fig.add_subplot(gs[1, 0])\n",
    "    _draw_feature_table(ax_lime_feat, lime_pairs, title=\"LIME: Feature    Value\")\n",
    "\n",
    "    ax_lime_metrics = fig.add_subplot(gs[1, 1])\n",
    "    _draw_metrics(ax_lime_metrics, m_lime)\n",
    "\n",
    "    # (B) SHAP 하단: 상위 토큰 테이블 + 메트릭\n",
    "    ax_shap_feat = fig.add_subplot(gs[3, 0])\n",
    "    _draw_feature_table(ax_shap_feat, shap_pairs, title=\"SHAP: Feature    Value\")\n",
    "\n",
    "    ax_shap_metrics = fig.add_subplot(gs[3, 1])\n",
    "    _draw_metrics(ax_shap_metrics, m_shap)\n",
    "\n",
    "    # (중간 빈 줄): 그림을 분리하는 제목\n",
    "    ax_sep = fig.add_subplot(gs[2, :])\n",
    "    ax_sep.axis(\"off\")\n",
    "    ax_sep.text(0.01, 0.5, \" \", fontsize=6)\n",
    "\n",
    "    if savepath is None:\n",
    "        savepath = f\"panel_{i:02d}_lime_shap.png\"\n",
    "    plt.savefig(savepath, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"saved:\", savepath)\n",
    "\n",
    "\n",
    "# ================== 사용법 ==================\n",
    "# 예: i=28, K=12로 저장\n",
    "# plot_lime_shap_panel(i=28, K=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5498352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer:  23%|██▎       | 7/30 [00:11<00:04,  4.98it/s]"
     ]
    }
   ],
   "source": [
    "import shap, numpy as np, pandas as pd\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AutoConfig\n",
    "import torch\n",
    "\n",
    "# --- 0) 모델/토크나이저/라벨 (이미 LIME에서 쓰던 그대로) ---\n",
    "MODEL_PATH = \"../models/nlbse/\"\n",
    "config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_PATH, config=config)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "display_labels = [\"bug\", \"enhancement\", \"question\"]\n",
    "if getattr(model.config, \"id2label\", None):\n",
    "    raw = [model.config.id2label[i] for i in range(model.config.num_labels)]\n",
    "    labels = (\n",
    "        display_labels if set(raw) == {f\"LABEL_{i}\" for i in range(len(raw))} else raw\n",
    "    )\n",
    "else:\n",
    "    labels = display_labels\n",
    "assert len(labels) == model.config.num_labels\n",
    "\n",
    "\n",
    "def predict(texts):\n",
    "    enc = tokenizer(\n",
    "        list(texts), return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "    )\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        probs = torch.softmax(model(**enc).logits, dim=-1).cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "\n",
    "# --- 1) 동일 샘플 로드 (LIME과 똑같이) ---\n",
    "df = pd.read_csv(\"balanced_eval_set.csv\").reset_index(drop=True)\n",
    "\n",
    "text_col_title = \"issue_title\"\n",
    "text_col_body = \"issue_body\"\n",
    "gold_col = \"issue_label\"\n",
    "\n",
    "\n",
    "def build_text(row, title_col=text_col_title, body_col=text_col_body, max_chars=800):\n",
    "    title = str(row.get(title_col, \"\"))\n",
    "    body = str(row.get(body_col, \"\"))[:max_chars]\n",
    "    return (title + \"\\n\\n\" + body).strip()\n",
    "\n",
    "\n",
    "samples = [build_text(row) for _, row in df.iterrows()]  # ★ LIME과 동일 입력\n",
    "\n",
    "# --- 2) SHAP 마스커/Explainer ---\n",
    "masker = shap.maskers.Text(\n",
    "    tokenizer=tokenizer, mask_token=(tokenizer.mask_token or \"[MASK]\")\n",
    ")\n",
    "explainer = shap.Explainer(predict, masker, output_names=labels, algorithm=\"partition\")\n",
    "\n",
    "# --- 3) SHAP 계산 ---\n",
    "shap_values = explainer(samples)  # len == N 샘플, 각 sv는 (토큰 × 클래스)\n",
    "\n",
    "# --- 4) 저장 (텍스트 플롯은 save_html 말고 .data를 직접 저장) ---\n",
    "for i, sv in enumerate(shap_values):\n",
    "    txt = samples[i]\n",
    "    probs = predict([txt])[0]\n",
    "    cls = int(np.argmax(probs))\n",
    "    predlab = labels[cls]\n",
    "    conf = float(probs[cls])\n",
    "    gold = str(df.iloc[i][gold_col])  # 실제 라벨\n",
    "\n",
    "    html_obj = shap.plots.text(sv[..., cls], display=False)  # 예측 클래스 기준\n",
    "    body = getattr(html_obj, \"data\", str(html_obj))\n",
    "\n",
    "    # HTML 상단에 gold/pred 표시\n",
    "    with open(f\"shap_{i:02d}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\n",
    "            f\"<meta charset='utf-8'>\\n\"\n",
    "            f\"<h2>[{i:02d}] gold: {gold} | pred: {predlab} (conf {conf:.2f})</h2>\\n\"\n",
    "            + body\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"[{i:02d}] gold={gold} | pred={predlab} (conf={conf:.2f}) → shap_{i:02d}.html\"\n",
    "    )\n",
    "\n",
    "# --- 5) (선택) shape 확인/진단 ---\n",
    "print(f\"#samples = {len(samples)}, #shap_values = {len(shap_values)}\")\n",
    "sv0 = shap_values[0]\n",
    "print(\"sv0.values shape (토큰×클래스):\", sv0.values.shape)  # (T, C)\n",
    "print(\"sv0.base_values shape (클래스):\", np.array(sv0.base_values).shape)  # (C,)\n",
    "print(\"정답 라벨 분포:\\n\", df[gold_col].value_counts())\n",
    "\n",
    "\n",
    "# --- 6) Faithfulness 지표 함수들 -------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# BERT 마스킹 토큰 ID\n",
    "mask_token_id = tokenizer.mask_token_id or tokenizer.convert_tokens_to_ids(\"[MASK]\")\n",
    "\n",
    "\n",
    "def predict_with_manual_mask(text, mask_indices, keep=False, max_length=512):\n",
    "    \"\"\"\n",
    "    WordPiece 기준으로 토큰을 선택적으로 [MASK] 처리한 뒤 모델 확률을 반환.\n",
    "    - keep=False: 상위 k 토큰을 [MASK]로 바꿔 제거 효과 (Compreh.)\n",
    "    - keep=True : 상위 k 토큰만 남기고 나머지는 [MASK] (Suff.)\n",
    "    \"\"\"\n",
    "    wp_tokens = tokenizer.tokenize(text)[: max_length - 2]  # [CLS]/[SEP] 고려\n",
    "    ids = tokenizer.convert_tokens_to_ids(wp_tokens)\n",
    "    input_ids = [tokenizer.cls_token_id] + ids + [tokenizer.sep_token_id]\n",
    "\n",
    "    if keep:\n",
    "        keep_set = set(mask_indices)\n",
    "        for t_idx in range(len(wp_tokens)):\n",
    "            pos = 1 + t_idx\n",
    "            if t_idx not in keep_set:\n",
    "                input_ids[pos] = mask_token_id\n",
    "    else:\n",
    "        for t_idx in mask_indices:\n",
    "            pos = 1 + t_idx\n",
    "            if 0 < pos < len(input_ids) - 1:  # [CLS]/[SEP] 보호\n",
    "                input_ids[pos] = mask_token_id\n",
    "\n",
    "    input_ids_tensor = torch.tensor([input_ids]).to(device)\n",
    "    attn = torch.ones_like(input_ids_tensor).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids=input_ids_tensor, attention_mask=attn).logits\n",
    "        probs = torch.softmax(logits, dim=-1).squeeze(0).detach().cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "\n",
    "def topk_token_indices_for_class(sv, class_idx: int, k: int = 10, use_abs: bool = True):\n",
    "    \"\"\"\n",
    "    SHAP Explanation sv에서 class_idx에 대한 상위 k 토큰 인덱스 반환.\n",
    "    sv.values shape == (num_tokens, num_classes)\n",
    "    \"\"\"\n",
    "    vals = sv.values[:, class_idx]\n",
    "    order = np.argsort(-np.abs(vals)) if use_abs else np.argsort(-vals)\n",
    "    return order[: min(k, len(order))].tolist()\n",
    "\n",
    "\n",
    "def faithfulness_metrics(\n",
    "    text: str, sv, k: int = 10, use_abs: bool = True, class_idx: int | None = None\n",
    "):\n",
    "    \"\"\"\n",
    "    한 샘플에 대한 Comprehensiveness / Sufficiency 계산.\n",
    "    - class_idx가 None이면 모델 예측 클래스(yhat) 기준으로 계산.\n",
    "    반환 dict: pred_class, p_full, p_drop, p_keep, comprehensiveness, sufficiency\n",
    "    \"\"\"\n",
    "    base_probs = predict([text])[0]\n",
    "    yhat = int(np.argmax(base_probs)) if class_idx is None else int(class_idx)\n",
    "    p_full = float(base_probs[yhat])\n",
    "\n",
    "    topk_idx = topk_token_indices_for_class(sv, yhat, k=k, use_abs=use_abs)\n",
    "\n",
    "    # Compreh.: 상위 k 제거\n",
    "    probs_drop = predict_with_manual_mask(text, topk_idx, keep=False)\n",
    "    p_drop = float(probs_drop[yhat])\n",
    "    compreh = p_full - p_drop\n",
    "\n",
    "    # Suff.: 상위 k만 유지\n",
    "    probs_keep = predict_with_manual_mask(text, topk_idx, keep=True)\n",
    "    p_keep = float(probs_keep[yhat])\n",
    "    suff = p_full - p_keep\n",
    "\n",
    "    return {\n",
    "        \"pred_class\": labels[yhat],\n",
    "        \"p_full\": p_full,\n",
    "        \"p_drop\": p_drop,\n",
    "        \"p_keep\": p_keep,\n",
    "        \"comprehensiveness\": compreh,\n",
    "        \"sufficiency\": suff,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_faithfulness(shap_values, samples, k: int = 10, use_abs: bool = True):\n",
    "    \"\"\"\n",
    "    전체 샘플에 대해 faithfulness 지표를 DataFrame으로 반환.\n",
    "    추가로 comp_norm(정규화), suff_abs(절댓값) 포함.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for i, (sv, txt) in enumerate(zip(shap_values, samples)):\n",
    "        m = faithfulness_metrics(txt, sv, k=k, use_abs=use_abs)\n",
    "        m[\"i\"] = i\n",
    "        m[\"gold\"] = str(df.iloc[i][gold_col])\n",
    "        m[\"k\"] = k\n",
    "        m[\"comp_norm\"] = m[\"comprehensiveness\"] / (m[\"p_full\"] + 1e-8)\n",
    "        m[\"suff_abs\"] = abs(m[\"sufficiency\"])\n",
    "        rows.append(m)\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd438da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# --- 보조 함수들 다시 정의 ---\n",
    "mask_token_id = tokenizer.mask_token_id or tokenizer.convert_tokens_to_ids(\"[MASK]\")\n",
    "\n",
    "\n",
    "def predict_with_manual_mask(text, mask_indices, keep=False, max_length=512):\n",
    "    # WordPiece 기준으로 토큰 마스킹 후 예측 확률 반환\n",
    "    wp_tokens = tokenizer.tokenize(text)[: max_length - 2]\n",
    "    ids = tokenizer.convert_tokens_to_ids(wp_tokens)\n",
    "    input_ids = [tokenizer.cls_token_id] + ids + [tokenizer.sep_token_id]\n",
    "\n",
    "    if keep:\n",
    "        keep_set = set(mask_indices)\n",
    "        for t_idx in range(len(wp_tokens)):\n",
    "            pos = 1 + t_idx\n",
    "            if t_idx not in keep_set:\n",
    "                input_ids[pos] = mask_token_id\n",
    "    else:\n",
    "        for t_idx in mask_indices:\n",
    "            pos = 1 + t_idx\n",
    "            if 0 < pos < len(input_ids) - 1:\n",
    "                input_ids[pos] = mask_token_id\n",
    "\n",
    "    input_ids_tensor = torch.tensor([input_ids]).to(device)\n",
    "    attn = torch.ones_like(input_ids_tensor).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids=input_ids_tensor, attention_mask=attn).logits\n",
    "        probs = torch.softmax(logits, dim=-1).squeeze(0).detach().cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "\n",
    "def topk_token_indices_for_class(sv, class_idx: int, k: int = 10, use_abs=True):\n",
    "    vals = sv.values[:, class_idx]  # (num_tokens,)\n",
    "    order = np.argsort(-np.abs(vals)) if use_abs else np.argsort(-vals)\n",
    "    return order[: min(k, len(order))].tolist()\n",
    "\n",
    "\n",
    "def faithfulness_metrics(text: str, sv, k: int = 10, use_abs=True):\n",
    "    base_probs = predict([text])[0]\n",
    "    yhat = int(base_probs.argmax())\n",
    "    p_full = float(base_probs[yhat])\n",
    "\n",
    "    topk_idx = topk_token_indices_for_class(sv, yhat, k=k, use_abs=use_abs)\n",
    "\n",
    "    probs_drop = predict_with_manual_mask(text, topk_idx, keep=False)\n",
    "    p_drop = float(probs_drop[yhat])\n",
    "    compreh = p_full - p_drop\n",
    "\n",
    "    probs_keep = predict_with_manual_mask(text, topk_idx, keep=True)\n",
    "    p_keep = float(probs_keep[yhat])\n",
    "    suff = p_full - p_keep\n",
    "\n",
    "    return {\n",
    "        \"pred_class\": labels[yhat],\n",
    "        \"p_full\": p_full,\n",
    "        \"p_drop\": p_drop,\n",
    "        \"p_keep\": p_keep,\n",
    "        \"comprehensiveness\": compreh,\n",
    "        \"sufficiency\": suff,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_faithfulness(shap_values, samples, k=10, use_abs=True):\n",
    "    rows = []\n",
    "    for i, sv in enumerate(shap_values):\n",
    "        m = faithfulness_metrics(samples[i], sv, k=k, use_abs=use_abs)\n",
    "        m[\"i\"] = i\n",
    "        m[\"gold\"] = str(df.iloc[i][gold_col])\n",
    "        m[\"k\"] = k\n",
    "        # 편의 지표\n",
    "        m[\"comp_norm\"] = m[\"comprehensiveness\"] / (m[\"p_full\"] + 1e-8)\n",
    "        m[\"suff_abs\"] = abs(m[\"sufficiency\"])\n",
    "        rows.append(m)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# --- 실행: 여러 k로 집계 ---\n",
    "results = []\n",
    "for k in [5, 10, 20]:\n",
    "    results.append(evaluate_faithfulness(shap_values, samples, k=k, use_abs=True))\n",
    "res = pd.concat(results, ignore_index=True)\n",
    "\n",
    "print(\"=== 전체 평균 ===\")\n",
    "print(\n",
    "    res.groupby(\"k\")[[\"comprehensiveness\", \"comp_norm\", \"sufficiency\", \"suff_abs\"]]\n",
    "    .mean()\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "print(\"\\n=== GOLD 라벨별 평균 ===\")\n",
    "print(\n",
    "    res.groupby([\"k\", \"gold\"])[\n",
    "        [\"comprehensiveness\", \"comp_norm\", \"sufficiency\", \"suff_abs\"]\n",
    "    ]\n",
    "    .mean()\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "# (선택) 파일로 저장\n",
    "# res.to_csv(\"faithfulness_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf516c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlbse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
