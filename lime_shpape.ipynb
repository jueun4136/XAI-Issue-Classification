{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8459c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"my_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642b69a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "issue_label\n",
      "bug            10\n",
      "enhancement    10\n",
      "question       10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SRC = \"../data/github-labels-top3-803k-test.csv\"\n",
    "label_col = \"issue_label\"\n",
    "target_labels = [\"bug\", \"enhancement\", \"question\"]\n",
    "n_per_class = 10\n",
    "\n",
    "df_all = pd.read_csv(SRC)\n",
    "df_all = df_all[df_all[label_col].isin(target_labels)]\n",
    "\n",
    "\n",
    "df_eval = (\n",
    "    df_all.groupby(label_col, group_keys=False)\n",
    "    .sample(n=n_per_class, random_state=200)\n",
    "    .sort_values([label_col])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_eval.to_csv(\"balanced_eval_set.csv\", index=False)\n",
    "\n",
    "print(df_eval[label_col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983b13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e22da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LIME 00] gold: bug | pred: bug (conf 0.93)\n",
      "\n",
      "[LIME 01] gold: bug | pred: bug (conf 0.93)\n",
      "\n",
      "[LIME 02] gold: bug | pred: bug (conf 0.79)\n",
      "\n",
      "[LIME 03] gold: bug | pred: bug (conf 0.90)\n",
      "\n",
      "[LIME 04] gold: bug | pred: bug (conf 0.95)\n",
      "\n",
      "[LIME 05] gold: bug | pred: bug (conf 0.94)\n",
      "\n",
      "[LIME 06] gold: bug | pred: bug (conf 0.95)\n",
      "\n",
      "[LIME 07] gold: bug | pred: bug (conf 0.95)\n",
      "\n",
      "[LIME 08] gold: bug | pred: question (conf 0.57)\n",
      "\n",
      "[LIME 09] gold: bug | pred: bug (conf 0.92)\n",
      "\n",
      "[LIME 10] gold: enhancement | pred: enhancement (conf 0.98)\n",
      "\n",
      "[LIME 11] gold: enhancement | pred: enhancement (conf 0.95)\n",
      "\n",
      "[LIME 12] gold: enhancement | pred: enhancement (conf 0.91)\n",
      "\n",
      "[LIME 13] gold: enhancement | pred: enhancement (conf 0.85)\n",
      "\n",
      "[LIME 14] gold: enhancement | pred: enhancement (conf 0.82)\n",
      "\n",
      "[LIME 15] gold: enhancement | pred: enhancement (conf 0.98)\n",
      "\n",
      "[LIME 16] gold: enhancement | pred: enhancement (conf 0.98)\n",
      "\n",
      "[LIME 17] gold: enhancement | pred: enhancement (conf 0.96)\n",
      "\n",
      "[LIME 18] gold: enhancement | pred: bug (conf 0.97)\n",
      "\n",
      "[LIME 19] gold: enhancement | pred: enhancement (conf 0.97)\n",
      "\n",
      "[LIME 20] gold: question | pred: question (conf 0.44)\n",
      "\n",
      "[LIME 21] gold: question | pred: bug (conf 0.56)\n",
      "\n",
      "[LIME 22] gold: question | pred: bug (conf 0.60)\n",
      "\n",
      "[LIME 23] gold: question | pred: enhancement (conf 0.63)\n",
      "\n",
      "[LIME 24] gold: question | pred: bug (conf 0.71)\n",
      "\n",
      "[LIME 25] gold: question | pred: question (conf 0.69)\n",
      "\n",
      "[LIME 26] gold: question | pred: question (conf 0.61)\n",
      "\n",
      "[LIME 27] gold: question | pred: enhancement (conf 0.48)\n",
      "\n",
      "[LIME 28] gold: question | pred: question (conf 0.92)\n",
      "\n",
      "[LIME 29] gold: question | pred: question (conf 0.41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 31it [00:55,  2.06s/it]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SHAP ready: 30 samples\n",
      "[SHAP 00] saved → shap_00.html (pred=bug, p=0.93)\n",
      "[SHAP 01] saved → shap_01.html (pred=bug, p=0.93)\n",
      "[SHAP 02] saved → shap_02.html (pred=bug, p=0.79)\n",
      "[SHAP 03] saved → shap_03.html (pred=bug, p=0.90)\n",
      "[SHAP 04] saved → shap_04.html (pred=bug, p=0.95)\n",
      "[SHAP 05] saved → shap_05.html (pred=bug, p=0.94)\n",
      "[SHAP 06] saved → shap_06.html (pred=bug, p=0.95)\n",
      "[SHAP 07] saved → shap_07.html (pred=bug, p=0.95)\n",
      "[SHAP 08] saved → shap_08.html (pred=question, p=0.57)\n",
      "[SHAP 09] saved → shap_09.html (pred=bug, p=0.92)\n",
      "[SHAP 10] saved → shap_10.html (pred=enhancement, p=0.98)\n",
      "[SHAP 11] saved → shap_11.html (pred=enhancement, p=0.95)\n",
      "[SHAP 12] saved → shap_12.html (pred=enhancement, p=0.91)\n",
      "[SHAP 13] saved → shap_13.html (pred=enhancement, p=0.85)\n",
      "[SHAP 14] saved → shap_14.html (pred=enhancement, p=0.82)\n",
      "[SHAP 15] saved → shap_15.html (pred=enhancement, p=0.98)\n",
      "[SHAP 16] saved → shap_16.html (pred=enhancement, p=0.98)\n",
      "[SHAP 17] saved → shap_17.html (pred=enhancement, p=0.96)\n",
      "[SHAP 18] saved → shap_18.html (pred=bug, p=0.97)\n",
      "[SHAP 19] saved → shap_19.html (pred=enhancement, p=0.97)\n",
      "[SHAP 20] saved → shap_20.html (pred=question, p=0.44)\n",
      "[SHAP 21] saved → shap_21.html (pred=bug, p=0.56)\n",
      "[SHAP 22] saved → shap_22.html (pred=bug, p=0.60)\n",
      "[SHAP 23] saved → shap_23.html (pred=enhancement, p=0.63)\n",
      "[SHAP 24] saved → shap_24.html (pred=bug, p=0.71)\n",
      "[SHAP 25] saved → shap_25.html (pred=question, p=0.69)\n",
      "[SHAP 26] saved → shap_26.html (pred=question, p=0.61)\n",
      "[SHAP 27] saved → shap_27.html (pred=enhancement, p=0.48)\n",
      "[SHAP 28] saved → shap_28.html (pred=question, p=0.92)\n",
      "[SHAP 29] saved → shap_29.html (pred=question, p=0.41)\n",
      "\n",
      "=== 전체 평균 ===\n",
      "    comprehensiveness  comp_norm  sufficiency  suff_abs\n",
      "k                                                      \n",
      "5               0.039      0.059        0.402     0.422\n",
      "10              0.111      0.162        0.367     0.389\n",
      "20              0.159      0.218        0.349     0.366\n",
      "\n",
      "=== GOLD 라벨별 평균 ===\n",
      "                comprehensiveness  comp_norm  sufficiency  suff_abs\n",
      "k  gold                                                            \n",
      "5  bug                      0.002     -0.004        0.566     0.566\n",
      "   enhancement              0.066      0.080        0.332     0.343\n",
      "   question                 0.048      0.102        0.309     0.356\n",
      "10 bug                      0.068      0.074        0.504     0.507\n",
      "   enhancement              0.126      0.142        0.289     0.307\n",
      "   question                 0.137      0.269        0.306     0.352\n",
      "20 bug                      0.111      0.139        0.502     0.502\n",
      "   enhancement              0.231      0.251        0.292     0.292\n",
      "   question                 0.134      0.264        0.253     0.305\n",
      "\n",
      "Saved: faithfulness_results.csv\n",
      "saved (LIME): lime_00.png\n",
      "saved (LIME): lime_01.png\n",
      "saved (LIME): lime_02.png\n",
      "saved (LIME): lime_03.png\n",
      "saved (LIME): lime_04.png\n",
      "saved (LIME): lime_05.png\n",
      "saved (LIME): lime_06.png\n",
      "saved (LIME): lime_07.png\n",
      "saved (LIME): lime_08.png\n",
      "saved (LIME): lime_09.png\n",
      "saved (LIME): lime_10.png\n",
      "saved (LIME): lime_11.png\n",
      "saved (LIME): lime_12.png\n",
      "saved (LIME): lime_13.png\n",
      "saved (LIME): lime_14.png\n",
      "saved (LIME): lime_15.png\n",
      "saved (LIME): lime_16.png\n",
      "saved (LIME): lime_17.png\n",
      "saved (LIME): lime_18.png\n",
      "saved (LIME): lime_19.png\n",
      "saved (LIME): lime_20.png\n",
      "saved (LIME): lime_21.png\n",
      "saved (LIME): lime_22.png\n",
      "saved (LIME): lime_23.png\n",
      "saved (LIME): lime_24.png\n",
      "saved (LIME): lime_25.png\n",
      "saved (LIME): lime_26.png\n",
      "saved (LIME): lime_27.png\n",
      "saved (LIME): lime_28.png\n",
      "saved (LIME): lime_29.png\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, AutoConfig\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from IPython.display import HTML, display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap, torch, os\n",
    "from typing import Optional\n",
    "\n",
    "MODEL_PATH = \"../models/nlbse/\"\n",
    "config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_PATH, config=config)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "display_labels = [\"bug\", \"enhancement\", \"question\"]\n",
    "if getattr(model.config, \"id2label\", None):\n",
    "    raw = [model.config.id2label[i] for i in range(model.config.num_labels)]\n",
    "    labels = (\n",
    "        display_labels if set(raw) == {f\"LABEL_{i}\" for i in range(len(raw))} else raw\n",
    "    )\n",
    "else:\n",
    "    labels = display_labels\n",
    "assert len(labels) == model.config.num_labels, \"num_labels와 labels 길이가 다릅니다.\"\n",
    "\n",
    "\n",
    "def predict(texts):\n",
    "    enc = tokenizer(\n",
    "        list(texts), return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "    )\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "        probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "\n",
    "CSV_PATH = \"balanced_eval_set.csv\"\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"{CSV_PATH} file not found. Run the first cell to create it.\"\n",
    "    )\n",
    "df = pd.read_csv(CSV_PATH).reset_index(drop=True)\n",
    "\n",
    "text_col_title = \"issue_title\"\n",
    "text_col_body = \"issue_body\"\n",
    "gold_col = \"issue_label\"\n",
    "\n",
    "\n",
    "def build_text(row, title_col=text_col_title, body_col=text_col_body, max_chars=800):\n",
    "    title = str(row.get(title_col, \"\"))\n",
    "    body = str(row.get(body_col, \"\"))[:max_chars]\n",
    "    return (title + \"\\n\\n\" + body).strip()\n",
    "\n",
    "\n",
    "samples = [build_text(row) for _, row in df.iterrows()]\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=labels, random_state=42)\n",
    "\n",
    "for n, row in enumerate(df.itertuples(index=False)):\n",
    "    txt = samples[n]\n",
    "    probs = predict([txt])[0]\n",
    "    idx = int(probs.argmax())\n",
    "    predlab = labels[idx]\n",
    "    conf = float(probs[idx])\n",
    "\n",
    "    print(\n",
    "        f\"\\n[LIME {n:02d}] gold: {getattr(row, gold_col)} | pred: {predlab} (conf {conf:.2f})\"\n",
    "    )\n",
    "    exp = explainer.explain_instance(\n",
    "        txt, predict, labels=[idx], num_features=12, num_samples=600\n",
    "    )\n",
    "\n",
    "    html = exp.as_html(text=txt)\n",
    "    # display(HTML(html))\n",
    "    with open(f\"lime_{n:02d}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "\n",
    "CSS_FIX = \"\"\"\n",
    "<style>\n",
    "  html, body { margin: 8px; font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; }\n",
    "  .shap { position: relative; }\n",
    "  .shap .top { margin-bottom: 36px !important; position: relative; z-index: 1; }\n",
    "  .shap .text, .shap .inputs, .shap .labels { position: relative; z-index: 9999 !important; }\n",
    "  .shap .text span { line-height: 1.65 !important; } \n",
    "  svg { overflow: visible !important; }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "masker = shap.maskers.Text(\n",
    "    tokenizer=tokenizer, mask_token=(tokenizer.mask_token or \"[MASK]\")\n",
    ")\n",
    "shap_explainer = shap.Explainer(\n",
    "    predict, masker, output_names=labels, algorithm=\"partition\"\n",
    ")\n",
    "\n",
    "shap_values = shap_explainer(samples)\n",
    "print(\"\\nSHAP ready:\", len(shap_values), \"samples\")\n",
    "\n",
    "for i, sv in enumerate(shap_values):\n",
    "    txt = samples[i]\n",
    "    probs = predict([txt])[0]\n",
    "    cls = int(np.argmax(probs))\n",
    "\n",
    "    html_obj = shap.plots.text(sv[..., cls], display=False)\n",
    "    body = getattr(html_obj, \"data\", str(html_obj))\n",
    "    page = f\"<!doctype html><meta charset='utf-8'>{CSS_FIX}{body}\"\n",
    "    out = f\"shap_{i:02d}.html\"\n",
    "    with open(out, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(page)\n",
    "    print(f\"[SHAP {i:02d}] saved → {out} (pred={labels[cls]}, p={probs[cls]:.2f})\")\n",
    "mask_token_id = tokenizer.mask_token_id or tokenizer.convert_tokens_to_ids(\"[MASK]\")\n",
    "\n",
    "\n",
    "def predict_with_manual_mask(text, mask_indices, keep=False, max_length=512):\n",
    "    wp_tokens = tokenizer.tokenize(text)[: max_length - 2]\n",
    "    ids = tokenizer.convert_tokens_to_ids(wp_tokens)\n",
    "    input_ids = [tokenizer.cls_token_id] + ids + [tokenizer.sep_token_id]\n",
    "\n",
    "    if keep:\n",
    "        keep_set = set(mask_indices)\n",
    "        for t_idx in range(len(wp_tokens)):\n",
    "            pos = 1 + t_idx\n",
    "            if t_idx not in keep_set:\n",
    "                input_ids[pos] = mask_token_id\n",
    "    else:\n",
    "        for t_idx in mask_indices:\n",
    "            pos = 1 + t_idx\n",
    "            if 0 < pos < len(input_ids) - 1:\n",
    "                input_ids[pos] = mask_token_id\n",
    "\n",
    "    input_ids_tensor = torch.tensor([input_ids]).to(device)\n",
    "    attn = torch.ones_like(input_ids_tensor).to(device)\n",
    "    with torch.no_grad():\n",
    "        probs = torch.softmax(\n",
    "            model(input_ids=input_ids_tensor, attention_mask=attn).logits, dim=-1\n",
    "        )\n",
    "    return probs.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def topk_token_indices_for_class(sv, class_idx: int, k: int = 10, use_abs: bool = True):\n",
    "    vals = sv.values[:, class_idx]  # (num_tokens,)\n",
    "    order = np.argsort(-np.abs(vals)) if use_abs else np.argsort(-vals)\n",
    "    return order[: min(k, len(order))].tolist()\n",
    "\n",
    "\n",
    "def faithfulness_metrics(\n",
    "    text: str, sv, k: int = 10, use_abs: bool = True, class_idx: Optional[int] = None\n",
    "):\n",
    "    base_probs = predict([text])[0]\n",
    "    yhat = int(np.argmax(base_probs)) if class_idx is None else int(class_idx)\n",
    "    p_full = float(base_probs[yhat])\n",
    "\n",
    "    topk_idx = topk_token_indices_for_class(sv, yhat, k=k, use_abs=use_abs)\n",
    "\n",
    "    p_drop = float(predict_with_manual_mask(text, topk_idx, keep=False)[yhat])\n",
    "    compreh = p_full - p_drop\n",
    "\n",
    "    p_keep = float(predict_with_manual_mask(text, topk_idx, keep=True)[yhat])\n",
    "    suff = p_full - p_keep\n",
    "\n",
    "    return {\n",
    "        \"pred_class\": labels[yhat],\n",
    "        \"p_full\": p_full,\n",
    "        \"p_drop\": p_drop,\n",
    "        \"p_keep\": p_keep,\n",
    "        \"comprehensiveness\": compreh,\n",
    "        \"sufficiency\": suff,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_faithfulness(shap_values, samples, k: int = 10, use_abs: bool = True):\n",
    "    rows = []\n",
    "    for i, (sv, txt) in enumerate(zip(shap_values, samples)):\n",
    "        m = faithfulness_metrics(txt, sv, k=k, use_abs=use_abs)\n",
    "        m[\"i\"] = i\n",
    "        m[\"gold\"] = str(df.iloc[i][gold_col])\n",
    "        m[\"k\"] = k\n",
    "        m[\"comp_norm\"] = m[\"comprehensiveness\"] / (m[\"p_full\"] + 1e-8)\n",
    "        m[\"suff_abs\"] = abs(m[\"sufficiency\"])\n",
    "        rows.append(m)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "ks = [5, 10, 20]\n",
    "res = pd.concat(\n",
    "    [evaluate_faithfulness(shap_values, samples, k=k) for k in ks], ignore_index=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    res.groupby(\"k\")[[\"comprehensiveness\", \"comp_norm\", \"sufficiency\", \"suff_abs\"]]\n",
    "    .mean()\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "print(\n",
    "    res.groupby([\"k\", \"gold\"])[\n",
    "        [\"comprehensiveness\", \"comp_norm\", \"sufficiency\", \"suff_abs\"]\n",
    "    ]\n",
    "    .mean()\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "res.to_csv(\"faithfulness_results.csv\", index=False)\n",
    "print(\"\\nSaved: faithfulness_results.csv\")\n",
    "\n",
    "\n",
    "from PIL import Image, ImageChops\n",
    "import os, glob, math\n",
    "\n",
    "\n",
    "def trim_png(path, out=None, bg=(255, 255, 255), margin=4):\n",
    "    im = Image.open(path).convert(\"RGB\")\n",
    "    bg_im = Image.new(\"RGB\", im.size, bg)\n",
    "    diff = ImageChops.difference(im, bg_im)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox is None:\n",
    "\n",
    "        out = out or path\n",
    "        im.save(out)\n",
    "        return out\n",
    "    left, top, right, bottom = bbox\n",
    "    left = max(0, left - margin)\n",
    "    top = max(0, top - margin)\n",
    "    right = min(im.width, right + margin)\n",
    "    bottom = min(im.height, bottom + margin)\n",
    "    im2 = im.crop((left, top, right, bottom))\n",
    "\n",
    "    out = out or path\n",
    "    im2.save(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def stack_wide_png(\n",
    "    path, out=None, max_panel_width=1200, n_cols=None, overlap=32, pad=12, bg=\"white\"\n",
    "):\n",
    "\n",
    "    im = Image.open(path).convert(\"RGBA\")\n",
    "    W, H = im.size\n",
    "    if n_cols is None:\n",
    "        n_cols = max(2, math.ceil(W / max_panel_width))\n",
    "    col_w = math.ceil(W / n_cols)\n",
    "\n",
    "    panels = []\n",
    "    x0 = 0\n",
    "    for i in range(n_cols):\n",
    "        x1 = min(W, x0 + col_w + (overlap if i < n_cols - 1 else 0))\n",
    "        panels.append(im.crop((x0, 0, x1, H)))\n",
    "        x0 += col_w\n",
    "\n",
    "    newW = max(p.width for p in panels)\n",
    "    newH = sum(p.height for p in panels) + pad * (len(panels) - 1)\n",
    "    bg_rgba = (255, 255, 255, 0) if bg == \"transparent\" else (255, 255, 255, 255)\n",
    "    out_im = Image.new(\"RGBA\", (newW, newH), bg_rgba)\n",
    "\n",
    "    y = 0\n",
    "    for p in panels:\n",
    "        out_im.paste(p, (0, y))\n",
    "        y += p.height + pad\n",
    "\n",
    "    root, ext = os.path.splitext(path)\n",
    "    out = out or f\"{root}_stack{n_cols}{ext}\"\n",
    "    out_im.save(out)\n",
    "    print(\"saved:\", out)\n",
    "    return out\n",
    "\n",
    "\n",
    "for p in sorted(glob.glob(\"Fig/*.png\")):\n",
    "    trim_png(p, margin=6)\n",
    "\n",
    "for p in sorted(glob.glob(\"Fig/shap_*.png\")):\n",
    "    stacked = stack_wide_png(p, n_cols=2, max_panel_width=1400, overlap=36, pad=18)\n",
    "    trim_png(stacked, margin=4)\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "def _open_driver(width=2400, scale=1.8):\n",
    "    opts = Options()\n",
    "    opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--disable-gpu\")\n",
    "    opts.add_argument(\"--hide-scrollbars\")\n",
    "    opts.add_argument(f\"--window-size={width},1200\")\n",
    "    opts.add_argument(f\"--force-device-scale-factor={scale}\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service, options=opts)\n",
    "\n",
    "\n",
    "def _smart_lime_bbox(driver, container_sel=\"#explanation\", min_area=35000):\n",
    "    script = \"\"\"\n",
    "    const root = document.querySelector(arguments[0]) || document.body;\n",
    "    const minArea = arguments[1];\n",
    "    const els = root.querySelectorAll(\"*\");\n",
    "    const boxes = [];\n",
    "    for (const el of els) {\n",
    "      const cs = getComputedStyle(el);\n",
    "      if (cs.display==='none' || cs.visibility==='hidden' || parseFloat(cs.opacity)===0) continue;\n",
    "      const r = el.getBoundingClientRect();\n",
    "      if (r.width < 2 || r.height < 2) continue;\n",
    "      const tag = el.tagName.toLowerCase();\n",
    "      const area = r.width * r.height;\n",
    "      const cls = (el.className || \"\").toString();\n",
    "      const importantText = /highlight|text|raw|table|explanation|prob|prediction/i.test(cls);\n",
    "      const graphic = (tag==='svg' || tag==='canvas' || tag==='img');\n",
    "      if (graphic || importantText || area > minArea) {\n",
    "        boxes.push(r);\n",
    "      }\n",
    "    }\n",
    "    if (boxes.length === 0) return null;\n",
    "    let minX=Infinity, minY=Infinity, maxX=-Infinity, maxY=-Infinity;\n",
    "    for (const b of boxes){ minX=Math.min(minX,b.left); minY=Math.min(minY,b.top); maxX=Math.max(maxX,b.right); maxY=Math.max(maxY,b.bottom); }\n",
    "    return {x:minX, y:minY, w:maxX-minX, h:maxY-minY};\n",
    "    \"\"\"\n",
    "    return driver.execute_script(script, container_sel, min_area)\n",
    "\n",
    "\n",
    "def _fallback_union_bbox(driver):\n",
    "    return driver.execute_script(\n",
    "        \"\"\"\n",
    "      const els = document.body.querySelectorAll('*');\n",
    "      let minX=Infinity,minY=Infinity,maxX=-Infinity,maxY=-Infinity, found=false;\n",
    "      for(const el of els){\n",
    "        const cs = getComputedStyle(el);\n",
    "        if(cs.display==='none'||cs.visibility==='hidden'||parseFloat(cs.opacity)===0) continue;\n",
    "        const r = el.getBoundingClientRect();\n",
    "        if(r.width<2||r.height<2) continue;\n",
    "        minX=Math.min(minX,r.left); minY=Math.min(minY,r.top);\n",
    "        maxX=Math.max(maxX,r.right); maxY=Math.max(maxY,r.bottom);\n",
    "        found=true;\n",
    "      }\n",
    "      if(!found) return null;\n",
    "      return {x:minX,y:minY,w:maxX-minX,h:maxY-minY};\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def html_to_png_lime(\n",
    "    html_path,\n",
    "    out_png,\n",
    "    container_candidates=(\n",
    "        \"#explanation\",\n",
    "        \".explanation\",\n",
    "        \".explanation-container\",\n",
    "        \".lime\",\n",
    "        \".lime-container\",\n",
    "    ),\n",
    "    width=2400,\n",
    "    scale=1.8,\n",
    "    pad_x=28,\n",
    "    pad_y=16,\n",
    "    extra_h=800,\n",
    "):\n",
    "    abspath = os.path.abspath(html_path).replace(\"\\\\\", \"/\")\n",
    "    url = \"file:///\" + abspath\n",
    "    drv = _open_driver(width=width, scale=scale)\n",
    "    try:\n",
    "        drv.get(url)\n",
    "        time.sleep(0.6)\n",
    "\n",
    "        doc_h = drv.execute_script(\n",
    "            \"return Math.max(document.body.scrollHeight, document.documentElement.scrollHeight);\"\n",
    "        )\n",
    "        drv.set_window_size(width, int(doc_h) + extra_h)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        rect = None\n",
    "        for sel in container_candidates:\n",
    "            rect = _smart_lime_bbox(drv, sel, min_area=35000)\n",
    "            if rect:\n",
    "                break\n",
    "        if rect is None:\n",
    "            rect = _fallback_union_bbox(drv)\n",
    "            if rect is None:\n",
    "                raise RuntimeError(\"LIME: no visible content to capture.\")\n",
    "\n",
    "        dpr = drv.execute_script(\"return window.devicePixelRatio || 1;\")\n",
    "        left = int((rect[\"x\"] - pad_x) * dpr)\n",
    "        top = int((rect[\"y\"] - pad_y) * dpr)\n",
    "        right = int((rect[\"x\"] + rect[\"w\"] + pad_x) * dpr)\n",
    "        bottom = int((rect[\"y\"] + rect[\"h\"] + pad_y) * dpr)\n",
    "\n",
    "        png = drv.get_screenshot_as_png()\n",
    "        img = Image.open(io.BytesIO(png))\n",
    "        left = max(0, left)\n",
    "        top = max(0, top)\n",
    "        right = min(img.width, right)\n",
    "        bottom = min(img.height, bottom)\n",
    "        img.crop((left, top, right, bottom)).save(out_png)\n",
    "        print(f\"saved (LIME): {out_png}\")\n",
    "    finally:\n",
    "        drv.quit()\n",
    "\n",
    "\n",
    "for p in sorted(glob.glob(\"lime_*.html\")):\n",
    "    html_to_png_lime(\n",
    "        p, p.replace(\".html\", \".png\"), width=2400, scale=1.9, pad_x=36, pad_y=18\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlbse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
